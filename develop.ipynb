{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021abd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from src.loadData import GraphDataset\n",
    "from src.utils import set_seed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from src.models import GNN, MLP, CompleteModel\n",
    "\n",
    "# Set the random seed\n",
    "set_seed()\n",
    "\n",
    "def add_zeros(data):\n",
    "    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Save checkpoints if required\n",
    "    if save_checkpoints:\n",
    "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_file)\n",
    "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(data_loader, model, device, calculate_accuracy=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(pred.cpu().numpy())\n",
    "            if calculate_accuracy:\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "    if calculate_accuracy:\n",
    "        accuracy = correct / total\n",
    "        return accuracy, predictions\n",
    "    return predictions\n",
    "\n",
    "def save_predictions(predictions, test_path):\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    submission_folder = os.path.join(script_dir, \"submission\")\n",
    "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "    \n",
    "    os.makedirs(submission_folder, exist_ok=True)\n",
    "    \n",
    "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "    \n",
    "    test_graph_ids = list(range(len(predictions)))\n",
    "    output_df = pd.DataFrame({\n",
    "        \"id\": test_graph_ids,\n",
    "        \"pred\": predictions\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "\n",
    "def plot_training_progress(train_losses, train_accuracies, output_dir):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "\n",
    "    # Save plots in the current directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    plt.close()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f731d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./datasets/C/test.json.gz\"\n",
    "train_path = \"./datasets/C/train.json.gz\"\n",
    "batch_size = 32\n",
    "\n",
    "# Prepare test dataset and loader\n",
    "test_dataset = GraphDataset(test_path, transform=add_zeros)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = GraphDataset(train_path, transform=add_zeros)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0a9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.4910, 0.0000, 0.0000, 0.0990, 0.0540])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.get(0).edge_attr[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc72cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8260]) torch.Size([2, 141262]) torch.Size([141262, 7]) torch.Size([8260])\n",
      "(tensor([[ 1.0827, -0.2646,  0.8171,  ...,  0.7688, -0.3303, -0.7539],\n",
      "        [ 0.3374,  0.4915,  0.5873,  ..., -0.2523, -1.4078,  0.1018],\n",
      "        [ 1.5704, -0.5685, -0.1056,  ..., -0.3058,  0.7888,  1.5209],\n",
      "        ...,\n",
      "        [-0.6141, -0.4504,  0.6907,  ...,  0.6537, -0.1442,  0.2400],\n",
      "        [-0.1318, -0.1694,  0.0414,  ..., -0.2727,  1.0073, -0.1876],\n",
      "        [-0.4725, -0.1344,  0.3407,  ..., -0.2777, -0.9140,  0.3938]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.2524, -0.2335,  0.0638,  ...,  0.5993,  0.1568, -0.4196],\n",
      "        [ 0.0683, -0.0586,  0.0170,  ...,  0.1022,  0.0387, -0.0323],\n",
      "        [ 0.6592, -0.3210, -0.0240,  ...,  1.2888,  0.1719, -0.7789],\n",
      "        ...,\n",
      "        [ 0.0686, -0.0879, -0.0084,  ...,  0.1451,  0.0221, -0.0109],\n",
      "        [ 0.0678, -0.0865, -0.0071,  ...,  0.1467,  0.0222, -0.0095],\n",
      "        [ 0.0682, -0.0897, -0.0070,  ...,  0.1430,  0.0254, -0.0117]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 1.9523e-01, -2.7615e-01, -2.1466e-01,  ...,  3.3279e-02,\n",
      "         -2.1328e-01,  1.8947e-02],\n",
      "        [-4.4466e-02,  1.4329e-02, -1.1499e-02,  ...,  6.2275e-02,\n",
      "         -2.1768e-02,  1.5549e-04],\n",
      "        [ 4.7737e-01, -8.4521e-01, -5.8940e-01,  ...,  9.8962e-02,\n",
      "         -3.1013e-01,  1.9077e-01],\n",
      "        ...,\n",
      "        [-1.8912e-02,  3.0293e-02, -2.7531e-02,  ...,  9.2710e-02,\n",
      "         -4.8227e-02,  5.3481e-02],\n",
      "        [-2.0309e-02,  2.8627e-02, -2.6876e-02,  ...,  9.2223e-02,\n",
      "         -5.0215e-02,  5.2816e-02],\n",
      "        [-1.9904e-02,  3.0046e-02, -2.5139e-02,  ...,  9.0484e-02,\n",
      "         -4.7686e-02,  5.5217e-02]], grad_fn=<AddmmBackward0>), tensor([[ 1.6026e-01, -1.6784e-01, -2.7332e-01, -1.3742e-01, -6.4806e-02,\n",
      "         -3.6322e-03],\n",
      "        [ 2.0522e-01, -9.4394e-02, -2.4075e-01, -1.6828e-01, -1.5705e-01,\n",
      "         -1.4596e-01],\n",
      "        [ 2.4863e-01, -1.1717e-01, -2.4395e-01, -6.5886e-02, -1.0743e-01,\n",
      "         -5.2496e-02],\n",
      "        [ 2.7729e-01, -4.5083e-02, -2.6096e-01, -7.0813e-02, -1.5724e-01,\n",
      "         -9.9833e-02],\n",
      "        [ 2.1053e-01, -1.0038e-01, -2.7726e-01, -1.2933e-01, -9.4443e-02,\n",
      "         -8.8586e-02],\n",
      "        [ 2.6613e-01, -1.5644e-01, -2.3544e-01, -7.8846e-02, -1.3698e-01,\n",
      "         -7.8308e-02],\n",
      "        [ 1.8851e-01, -1.6944e-01, -2.5706e-01, -6.8084e-02, -5.1047e-02,\n",
      "         -8.2439e-02],\n",
      "        [ 2.9363e-01, -1.5355e-01, -3.1269e-01, -1.5613e-01, -1.2377e-01,\n",
      "         -2.2834e-02],\n",
      "        [ 2.2085e-01, -7.8806e-02, -2.4016e-01, -1.7051e-01, -1.3604e-01,\n",
      "         -9.9009e-02],\n",
      "        [ 1.7970e-01, -1.8599e-01, -4.6489e-01, -2.4035e-01,  1.2570e-01,\n",
      "         -7.2286e-05],\n",
      "        [ 1.8000e-01, -1.1055e-01, -2.7970e-01, -2.7438e-01,  7.5542e-03,\n",
      "         -7.9504e-02],\n",
      "        [ 2.3587e-01, -1.2244e-01, -1.6570e-01, -6.9724e-02, -1.6069e-01,\n",
      "         -6.5513e-02],\n",
      "        [ 2.8002e-01, -1.0926e-01, -2.6573e-01, -1.1472e-01, -9.5393e-02,\n",
      "         -8.5586e-02],\n",
      "        [ 2.2399e-01, -1.6753e-01, -2.6731e-01, -7.7870e-02, -1.4095e-01,\n",
      "         -6.3583e-02],\n",
      "        [ 2.4325e-01, -4.3461e-02, -1.1767e-01,  9.5140e-02, -1.2914e-01,\n",
      "         -1.3508e-01],\n",
      "        [ 2.6242e-01, -1.3469e-01, -2.3287e-01, -7.6960e-02, -7.4785e-02,\n",
      "         -4.7514e-02],\n",
      "        [ 2.5490e-01, -1.9403e-01, -2.6905e-01, -7.9610e-02, -8.1500e-02,\n",
      "         -7.4571e-02],\n",
      "        [ 2.6423e-01, -4.6639e-02, -1.5565e-01, -5.1948e-03,  1.3831e-02,\n",
      "         -1.7292e-01],\n",
      "        [ 2.5652e-01, -1.8179e-01, -2.5644e-01, -6.5157e-02, -1.3387e-01,\n",
      "         -6.1373e-02],\n",
      "        [ 2.5749e-01, -5.7624e-02, -2.5883e-01, -7.8911e-02, -6.1112e-02,\n",
      "         -1.1584e-01],\n",
      "        [ 1.7698e-01, -1.1610e-01, -1.5978e-01, -4.3776e-02, -1.2950e-01,\n",
      "         -8.9945e-02],\n",
      "        [ 1.5507e-01, -1.3177e-01, -3.6724e-01, -2.6585e-01, -8.9056e-02,\n",
      "         -2.3390e-03],\n",
      "        [ 2.1720e-01, -1.4268e-01, -2.4949e-01, -7.4887e-02, -1.4258e-01,\n",
      "         -4.8195e-02],\n",
      "        [ 2.5922e-01, -1.0983e-01, -2.3261e-01, -1.1722e-01, -8.2721e-02,\n",
      "         -1.0136e-01],\n",
      "        [ 2.1074e-01, -1.1390e-01, -2.8059e-01, -1.5417e-01, -8.4130e-02,\n",
      "         -8.9150e-02],\n",
      "        [ 2.5499e-01, -8.5944e-02, -2.5079e-01, -1.0000e-01, -1.0893e-01,\n",
      "         -1.0325e-01],\n",
      "        [ 2.5922e-01, -1.7500e-01, -2.6907e-01, -9.9986e-02, -1.1490e-01,\n",
      "         -1.4725e-01],\n",
      "        [ 2.3343e-01, -1.1193e-01, -3.6815e-01, -1.6372e-01, -4.6816e-02,\n",
      "         -5.5372e-02],\n",
      "        [ 2.1937e-01, -5.7018e-02, -2.3165e-01, -1.6159e-01, -9.4603e-02,\n",
      "         -7.0334e-02],\n",
      "        [ 2.4639e-01, -1.0102e-01, -2.2180e-01, -8.7641e-02, -1.0762e-01,\n",
      "         -2.9082e-02],\n",
      "        [ 3.0148e-01, -3.5996e-01, -3.8609e-01, -1.0099e-01, -1.8103e-01,\n",
      "         -4.4365e-03],\n",
      "        [ 1.9145e-01, -1.5435e-01, -1.8614e-01, -5.1039e-02, -1.3584e-01,\n",
      "         -8.0548e-02]], grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8028]) torch.Size([2, 144098]) torch.Size([144098, 7]) torch.Size([8028])\n",
      "(tensor([[ 1.1180, -0.8016,  1.8243,  ...,  1.4974,  0.9163, -1.5628],\n",
      "        [-0.1063,  0.4009,  1.2692,  ..., -2.1880, -1.4542, -1.1481],\n",
      "        [-0.0480, -0.1753,  0.5134,  ..., -0.0276,  0.4867, -1.1023],\n",
      "        ...,\n",
      "        [-0.0574, -0.5597, -0.7063,  ..., -0.7540,  0.3935, -1.0414],\n",
      "        [ 0.6009, -1.3725,  0.6994,  ...,  1.2843, -2.6448, -1.5978],\n",
      "        [-0.2654, -0.8854, -0.5173,  ...,  0.4955, -1.3385,  1.4254]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.5252, -0.3281,  0.1889,  ...,  0.4525,  0.6476, -0.2684],\n",
      "        [ 0.2062, -0.0591,  0.0258,  ...,  0.3880,  0.5591, -0.4471],\n",
      "        [ 0.3410, -0.1105,  0.0969,  ...,  0.1848,  0.3902, -0.0603],\n",
      "        ...,\n",
      "        [ 0.0966, -0.0624,  0.0223,  ...,  0.1794, -0.0278, -0.0282],\n",
      "        [ 0.0956, -0.0674,  0.0225,  ...,  0.1797, -0.0163, -0.0376],\n",
      "        [ 0.0937, -0.0643,  0.0171,  ...,  0.1914, -0.0212, -0.0277]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2813, -0.7404,  0.0815,  ...,  0.3415, -0.6446,  0.3236],\n",
      "        [ 0.2609, -0.5066,  0.0596,  ...,  0.1755, -0.2736,  0.3055],\n",
      "        [ 0.0858, -0.2975,  0.1765,  ...,  0.2844, -0.3281,  0.1262],\n",
      "        ...,\n",
      "        [-0.0401, -0.0279, -0.0151,  ...,  0.0976, -0.0781,  0.0692],\n",
      "        [-0.0430, -0.0288, -0.0126,  ...,  0.0859, -0.0745,  0.0715],\n",
      "        [-0.0399, -0.0251, -0.0103,  ...,  0.0997, -0.0766,  0.0797]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.3415, -0.1821, -0.3219, -0.1217, -0.1397, -0.0929],\n",
      "        [ 0.3053, -0.1229, -0.3299, -0.1523, -0.0907, -0.0657],\n",
      "        [ 0.2449, -0.1291, -0.2772, -0.0934, -0.0806, -0.0882],\n",
      "        [ 0.2176, -0.2586, -0.2231, -0.1108, -0.2284, -0.0647],\n",
      "        [ 0.2031, -0.1103, -0.2606, -0.1072, -0.1082, -0.0729],\n",
      "        [ 0.2422, -0.1304, -0.3225, -0.1697, -0.0485, -0.0832],\n",
      "        [ 0.2348, -0.0993, -0.2684, -0.0893, -0.1368, -0.0622],\n",
      "        [ 0.2637, -0.2060, -0.2856, -0.0260, -0.1870, -0.0357],\n",
      "        [ 0.2286, -0.0853, -0.1949, -0.1426, -0.1785, -0.1327],\n",
      "        [ 0.2078, -0.0930, -0.2580, -0.0620, -0.1001, -0.0538],\n",
      "        [ 0.2971, -0.1185, -0.1103,  0.0275, -0.2619,  0.0198],\n",
      "        [ 0.2087, -0.2081, -0.2508, -0.1006, -0.1252, -0.0026],\n",
      "        [ 0.2744,  0.0034, -0.2902, -0.0434, -0.0644, -0.0939],\n",
      "        [ 0.1146, -0.0728, -0.2155, -0.1206, -0.1189, -0.1118],\n",
      "        [ 0.2220, -0.1096, -0.2508, -0.1293, -0.2072, -0.0800],\n",
      "        [ 0.1717, -0.1446, -0.2586, -0.1461, -0.1429, -0.0465],\n",
      "        [ 0.2691, -0.1870, -0.2605, -0.0886, -0.0884, -0.0493],\n",
      "        [ 0.1508, -0.1288, -0.2773, -0.1186, -0.0920, -0.0342],\n",
      "        [ 0.0834,  0.0104, -0.3430, -0.3153,  0.1290, -0.1200],\n",
      "        [ 0.2644, -0.1366, -0.2480, -0.1058, -0.1207, -0.0766],\n",
      "        [ 0.2559, -0.2307, -0.3031, -0.1639, -0.0896, -0.0475],\n",
      "        [ 0.2432, -0.1167, -0.2875, -0.1371, -0.1273, -0.0402],\n",
      "        [ 0.1999, -0.1623, -0.3090, -0.2283, -0.0607, -0.0401],\n",
      "        [ 0.2589, -0.1223, -0.2056, -0.1255, -0.2029, -0.1087],\n",
      "        [ 0.2031, -0.0778, -0.2623, -0.0904, -0.0726, -0.0452],\n",
      "        [ 0.2887, -0.1469, -0.2748, -0.1225, -0.1314, -0.0662],\n",
      "        [ 0.2511, -0.0875, -0.2616, -0.1254, -0.0805, -0.1012],\n",
      "        [ 0.1718, -0.1240, -0.2229, -0.1201, -0.0500, -0.0932],\n",
      "        [ 0.3198, -0.1392, -0.2895, -0.1063, -0.0460, -0.0345],\n",
      "        [ 0.2593, -0.1536, -0.2716, -0.0683, -0.1399, -0.0993],\n",
      "        [ 0.1845, -0.0954, -0.2894, -0.1563, -0.0493, -0.1033],\n",
      "        [ 0.2753, -0.1886, -0.1916, -0.1138, -0.0855, -0.1022]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7827]) torch.Size([2, 160234]) torch.Size([160234, 7]) torch.Size([7827])\n",
      "(tensor([[ 0.4979, -0.5124, -0.1190,  ...,  0.9080, -0.8816,  0.2783],\n",
      "        [-1.4738,  0.0455, -0.0921,  ..., -0.0095,  1.0767,  0.4458],\n",
      "        [-0.7112, -0.8887, -0.3270,  ...,  1.0704,  1.1359,  0.9798],\n",
      "        ...,\n",
      "        [-0.8867,  0.9141, -1.5393,  ..., -0.5163, -0.1858,  0.2203],\n",
      "        [ 0.3172, -3.4358, -0.3362,  ...,  0.3951, -0.4786, -0.2637],\n",
      "        [-0.1613, -0.2422,  2.9386,  ...,  1.4114, -1.4124, -0.7988]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0516, -0.0705,  0.0480,  ...,  0.1501,  0.0488, -0.0556],\n",
      "        [ 0.0492, -0.0547,  0.0396,  ...,  0.1585,  0.0206, -0.0376],\n",
      "        [ 0.0585, -0.0636,  0.0420,  ...,  0.1562,  0.0161, -0.0423],\n",
      "        ...,\n",
      "        [ 0.0900, -0.0741,  0.0285,  ...,  0.1904, -0.0104, -0.0388],\n",
      "        [ 0.0793, -0.0833,  0.0249,  ...,  0.1880,  0.0005, -0.0286],\n",
      "        [ 0.0782, -0.0798,  0.0261,  ...,  0.1900, -0.0003, -0.0296]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0498, -0.0064, -0.0120,  ...,  0.0538, -0.0275,  0.0658],\n",
      "        [-0.0484, -0.0109,  0.0011,  ...,  0.0602, -0.0481,  0.0534],\n",
      "        [-0.0556, -0.0046, -0.0153,  ...,  0.0778, -0.0504,  0.0601],\n",
      "        ...,\n",
      "        [-0.0465, -0.0106, -0.0242,  ...,  0.1084, -0.0533,  0.0663],\n",
      "        [-0.0396, -0.0008, -0.0139,  ...,  0.0963, -0.0571,  0.0734],\n",
      "        [-0.0414, -0.0025, -0.0163,  ...,  0.1002, -0.0553,  0.0679]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1507, -0.0341, -0.1541, -0.0893,  0.0112, -0.1511],\n",
      "        [ 0.1934, -0.0729, -0.2989, -0.1007, -0.0775, -0.0316],\n",
      "        [ 0.2256, -0.0615, -0.2190, -0.1321, -0.1040, -0.0928],\n",
      "        [ 0.2219, -0.1389, -0.4006, -0.0719,  0.0268, -0.0737],\n",
      "        [ 0.2374, -0.1171, -0.2573, -0.0497, -0.1540, -0.1086],\n",
      "        [ 0.2379, -0.1834, -0.2971, -0.1495, -0.1724, -0.0760],\n",
      "        [ 0.1934, -0.1033, -0.2459, -0.0979, -0.1411, -0.1019],\n",
      "        [ 0.2102, -0.1019, -0.2735, -0.1084, -0.1134, -0.0214],\n",
      "        [ 0.2114, -0.1036, -0.2539, -0.1293, -0.0943, -0.1000],\n",
      "        [ 0.1911, -0.1021, -0.3021, -0.1988, -0.0959, -0.0389],\n",
      "        [ 0.2189, -0.0512, -0.2350, -0.0907, -0.1075, -0.0968],\n",
      "        [ 0.2350, -0.1517, -0.2695, -0.0691, -0.1358, -0.0889],\n",
      "        [ 0.1806, -0.0887, -0.2618, -0.0904, -0.1174, -0.0848],\n",
      "        [ 0.2703, -0.2340, -0.2955, -0.1086, -0.0792, -0.0672],\n",
      "        [ 0.1854, -0.0183, -0.2770, -0.1413, -0.0073, -0.1118],\n",
      "        [ 0.2493, -0.1456, -0.2535, -0.1309, -0.0827, -0.1120],\n",
      "        [ 0.2945, -0.1235, -0.3038, -0.1787, -0.1468, -0.0946],\n",
      "        [ 0.3474, -0.2040, -0.3181, -0.0388, -0.1072, -0.0825],\n",
      "        [ 0.2470, -0.1313, -0.2992, -0.1369, -0.1398, -0.0548],\n",
      "        [ 0.2813, -0.1446, -0.2602, -0.1261, -0.1204, -0.0315],\n",
      "        [ 0.2510, -0.0626, -0.2720, -0.1588, -0.0475, -0.0894],\n",
      "        [ 0.2436, -0.1896, -0.2903, -0.1101, -0.1517, -0.0550],\n",
      "        [ 0.1739, -0.1098, -0.2237, -0.1251, -0.1642, -0.1393],\n",
      "        [ 0.1836,  0.0013, -0.2662,  0.0402, -0.2306, -0.0013],\n",
      "        [ 0.2420, -0.0552, -0.2359, -0.0771, -0.0874, -0.1289],\n",
      "        [ 0.2536, -0.1108, -0.2845, -0.0787, -0.1615, -0.0722],\n",
      "        [ 0.2163, -0.2155, -0.3528, -0.1214, -0.0837, -0.0393],\n",
      "        [ 0.2294, -0.1477, -0.2915, -0.1584, -0.1137, -0.1023],\n",
      "        [ 0.2108, -0.1260, -0.2748, -0.1281, -0.1435, -0.0865],\n",
      "        [ 0.2480, -0.1288, -0.2020, -0.0900, -0.0955, -0.0718],\n",
      "        [ 0.2470, -0.1519, -0.4807, -0.2419,  0.0819,  0.0905],\n",
      "        [ 0.2457, -0.1032, -0.2364, -0.1523, -0.1855, -0.1449]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8000]) torch.Size([2, 139774]) torch.Size([139774, 7]) torch.Size([8000])\n",
      "(tensor([[-0.3895, -1.6802,  2.6642,  ...,  1.9112, -0.2913,  0.7573],\n",
      "        [-0.8545, -0.8560, -0.4689,  ...,  1.6040, -0.1672,  1.8511],\n",
      "        [-0.7134,  0.1157,  0.1068,  ...,  0.1229,  0.4852,  1.7876],\n",
      "        ...,\n",
      "        [ 0.8250, -0.3349, -0.4007,  ...,  0.1213,  0.2381,  0.4482],\n",
      "        [ 1.9526, -0.0381,  0.7647,  ..., -1.9138, -1.6917, -0.7346],\n",
      "        [ 1.3094, -0.7932, -1.0511,  ...,  1.7087, -0.4605, -0.1089]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 7.3858e-02, -6.5330e-02,  1.4130e-02,  ...,  1.7573e-01,\n",
      "         -2.0927e-03, -2.6901e-02],\n",
      "        [ 7.2705e-02, -6.2366e-02,  1.0142e-02,  ...,  1.8924e-01,\n",
      "         -1.3229e-02, -2.4005e-02],\n",
      "        [ 8.8288e-02, -1.0602e-01,  1.4844e-02,  ...,  6.1847e-02,\n",
      "          8.4276e-02, -3.9959e-02],\n",
      "        ...,\n",
      "        [ 9.0370e-02, -5.5173e-02, -1.4523e-04,  ...,  2.1375e-01,\n",
      "         -2.5058e-02, -2.6789e-02],\n",
      "        [ 9.3400e-02, -5.2215e-02, -9.8143e-04,  ...,  2.1583e-01,\n",
      "         -1.7410e-02, -3.2808e-02],\n",
      "        [ 9.3412e-02, -6.1186e-02, -2.1667e-03,  ...,  2.0345e-01,\n",
      "         -2.2214e-02, -3.0855e-02]], grad_fn=<AddmmBackward0>), tensor([[-0.0405, -0.0050, -0.0291,  ...,  0.0825, -0.0546,  0.0615],\n",
      "        [-0.0431, -0.0071, -0.0241,  ...,  0.0841, -0.0611,  0.0604],\n",
      "        [-0.0022,  0.0304, -0.0157,  ...,  0.0331, -0.0070,  0.0430],\n",
      "        ...,\n",
      "        [-0.0506, -0.0101, -0.0298,  ...,  0.1085, -0.0643,  0.0580],\n",
      "        [-0.0503, -0.0089, -0.0255,  ...,  0.1095, -0.0591,  0.0665],\n",
      "        [-0.0444, -0.0089, -0.0282,  ...,  0.1046, -0.0603,  0.0619]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2730, -0.1498, -0.2771, -0.1031, -0.1459, -0.0295],\n",
      "        [ 0.1693, -0.1160, -0.2424, -0.1923, -0.1471, -0.1114],\n",
      "        [ 0.3131, -0.1069, -0.2638, -0.0604, -0.0819, -0.0948],\n",
      "        [ 0.2085, -0.1308, -0.2527, -0.1316, -0.1396, -0.0698],\n",
      "        [ 0.2531, -0.1242, -0.2727, -0.1703, -0.1006, -0.0293],\n",
      "        [ 0.2671, -0.1319, -0.2788, -0.1251, -0.1792, -0.1134],\n",
      "        [ 0.3306, -0.1490, -0.3639, -0.0837, -0.0906,  0.0205],\n",
      "        [ 0.2515, -0.2207, -0.3083, -0.1716, -0.1167, -0.0189],\n",
      "        [ 0.2269, -0.1177, -0.2525, -0.1249, -0.1071, -0.0333],\n",
      "        [ 0.1987, -0.0540, -0.2558, -0.1047, -0.0952, -0.1349],\n",
      "        [ 0.1709, -0.1033, -0.2687, -0.1722, -0.1452, -0.0553],\n",
      "        [ 0.1482, -0.1044, -0.2530, -0.1372, -0.0975, -0.0932],\n",
      "        [ 0.1704, -0.1358, -0.4424, -0.1565, -0.0111, -0.1993],\n",
      "        [ 0.1982, -0.1801, -0.2533, -0.0443, -0.1253, -0.0372],\n",
      "        [ 0.0853, -0.1131, -0.1348, -0.1212, -0.1411, -0.0683],\n",
      "        [ 0.1921, -0.1435, -0.2543, -0.1625, -0.1084, -0.0934],\n",
      "        [ 0.2103, -0.0881, -0.2515, -0.1329, -0.1710, -0.0652],\n",
      "        [ 0.2922, -0.1231, -0.2813, -0.1420, -0.0724, -0.0702],\n",
      "        [ 0.2360, -0.0803, -0.2538, -0.1465, -0.1308, -0.1575],\n",
      "        [ 0.2083, -0.1078, -0.2345, -0.0840, -0.1488, -0.0924],\n",
      "        [ 0.1730, -0.0819, -0.3292, -0.2550,  0.0623, -0.0324],\n",
      "        [ 0.2365, -0.0931, -0.2429, -0.1700, -0.1065, -0.0837],\n",
      "        [ 0.1951, -0.0541, -0.2027, -0.1281, -0.1288, -0.0991],\n",
      "        [ 0.1776, -0.2111, -0.4327, -0.2936,  0.0081,  0.0196],\n",
      "        [ 0.2604, -0.1499, -0.2288, -0.0830, -0.1074, -0.0554],\n",
      "        [ 0.1975, -0.1065, -0.2459, -0.1652, -0.1525, -0.0352],\n",
      "        [ 0.2035, -0.1358, -0.2533, -0.0961, -0.1668, -0.1117],\n",
      "        [ 0.2409, -0.0741, -0.3105, -0.1286, -0.1147, -0.0364],\n",
      "        [ 0.2102, -0.1241, -0.3349, -0.1914, -0.0700, -0.0085],\n",
      "        [ 0.2250, -0.1770, -0.2907, -0.1152, -0.1165, -0.0305],\n",
      "        [ 0.1756, -0.0702, -0.0914, -0.0698, -0.1422, -0.0232],\n",
      "        [ 0.2259, -0.1072, -0.2475, -0.1328, -0.0810, -0.0995]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8213]) torch.Size([2, 147308]) torch.Size([147308, 7]) torch.Size([8213])\n",
      "(tensor([[ 0.1152, -1.2284,  0.5065,  ...,  1.1743, -0.7089, -1.9340],\n",
      "        [ 1.4563, -0.5818, -1.0418,  ..., -0.3398, -0.5888,  1.3493],\n",
      "        [-1.6745,  1.9539, -0.4625,  ...,  0.2035,  0.9234, -0.9525],\n",
      "        ...,\n",
      "        [ 2.3939, -0.6838, -0.1051,  ..., -0.8382,  0.0416, -0.6750],\n",
      "        [ 0.7915, -0.9616,  0.6556,  ...,  1.2118,  2.3849,  1.3134],\n",
      "        [ 0.6474,  1.0261, -0.4465,  ..., -0.6722,  1.2001,  0.7638]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0576, -0.0920,  0.0545,  ...,  0.1234,  0.0348, -0.0728],\n",
      "        [ 0.1151, -0.0926,  0.0064,  ...,  0.2695,  0.1068, -0.1393],\n",
      "        [ 0.0814, -0.0818,  0.0088,  ...,  0.1391,  0.0158, -0.0172],\n",
      "        ...,\n",
      "        [ 0.0865, -0.0693,  0.0314,  ...,  0.1722,  0.0173, -0.0280],\n",
      "        [ 0.0922, -0.0676,  0.0271,  ...,  0.1744,  0.0113, -0.0242],\n",
      "        [ 0.0900, -0.0681,  0.0255,  ...,  0.1796,  0.0109, -0.0222]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0098, -0.0196,  0.0067,  ...,  0.0500, -0.0495, -0.0090],\n",
      "        [ 0.0879, -0.1533, -0.1502,  ...,  0.0257, -0.0889,  0.0810],\n",
      "        [-0.0118,  0.0173, -0.0209,  ...,  0.0983, -0.0473,  0.0467],\n",
      "        ...,\n",
      "        [-0.0311, -0.0103, -0.0083,  ...,  0.0924, -0.0736,  0.0751],\n",
      "        [-0.0312, -0.0098, -0.0108,  ...,  0.0981, -0.0764,  0.0744],\n",
      "        [-0.0324, -0.0097, -0.0076,  ...,  0.0974, -0.0807,  0.0771]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2112, -0.1408, -0.2295, -0.0955, -0.1026, -0.0995],\n",
      "        [ 0.2600, -0.1858, -0.3091, -0.0697, -0.0858, -0.0464],\n",
      "        [ 0.2790, -0.1861, -0.2807, -0.1630, -0.1716,  0.0067],\n",
      "        [ 0.1719, -0.0797, -0.2534, -0.1402, -0.1057, -0.0374],\n",
      "        [ 0.2196, -0.1463, -0.3025, -0.1124, -0.0806, -0.0646],\n",
      "        [ 0.2090, -0.2187, -0.3065, -0.1958, -0.1273, -0.0121],\n",
      "        [ 0.2505, -0.1812, -0.3034, -0.1466, -0.0950, -0.0897],\n",
      "        [ 0.1751, -0.1163, -0.2765, -0.1472, -0.1808, -0.0911],\n",
      "        [ 0.2163, -0.1527, -0.3284, -0.1562,  0.0137, -0.0442],\n",
      "        [ 0.2116, -0.1575, -0.2793, -0.2329, -0.1108, -0.0637],\n",
      "        [ 0.2957, -0.1809, -0.2766, -0.1269, -0.1516, -0.0493],\n",
      "        [ 0.2636, -0.1153, -0.2597, -0.0342, -0.1621, -0.0599],\n",
      "        [ 0.2925, -0.1317, -0.2579, -0.1004, -0.1042, -0.0351],\n",
      "        [ 0.2315, -0.0977, -0.2923, -0.1093, -0.1005, -0.0816],\n",
      "        [ 0.2372, -0.1347, -0.3240, -0.1231, -0.1288, -0.0064],\n",
      "        [ 0.1210, -0.0767, -0.2963, -0.1480, -0.1143, -0.1816],\n",
      "        [ 0.2746, -0.1484, -0.2806, -0.0522, -0.0971, -0.0839],\n",
      "        [ 0.2219, -0.0938, -0.2738, -0.0950, -0.1183, -0.0931],\n",
      "        [ 0.2243, -0.1457, -0.2500, -0.1773, -0.1582, -0.0567],\n",
      "        [ 0.2599, -0.1181, -0.3096, -0.0674, -0.0684, -0.1163],\n",
      "        [ 0.1874, -0.0825, -0.2843, -0.1563, -0.0745, -0.0699],\n",
      "        [ 0.1876, -0.1147, -0.3359, -0.1401, -0.1014, -0.1065],\n",
      "        [ 0.2194, -0.1138, -0.2263, -0.1211, -0.1657, -0.0533],\n",
      "        [ 0.2270, -0.1013, -0.2407, -0.1222, -0.1271, -0.0578],\n",
      "        [ 0.1555, -0.0365, -0.2795, -0.1518,  0.0150, -0.0355],\n",
      "        [ 0.2450, -0.0594, -0.2456, -0.1244, -0.0770, -0.0421],\n",
      "        [ 0.2184, -0.1793, -0.2477, -0.0482, -0.0717, -0.0806],\n",
      "        [ 0.2562, -0.1125, -0.2758, -0.1839, -0.1371, -0.0416],\n",
      "        [ 0.1878, -0.1116, -0.1887, -0.0956, -0.0517, -0.0739],\n",
      "        [ 0.2167, -0.1396, -0.3980, -0.2805, -0.0022,  0.0129],\n",
      "        [ 0.1924, -0.1587, -0.3209, -0.2209, -0.0403, -0.0817],\n",
      "        [ 0.2162, -0.1074, -0.2623, -0.1096, -0.1896, -0.0607]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8602]) torch.Size([2, 169104]) torch.Size([169104, 7]) torch.Size([8602])\n",
      "(tensor([[ 0.0962, -0.7558,  0.6447,  ...,  0.1293, -0.8323, -1.6945],\n",
      "        [ 0.8267, -0.5739, -0.4097,  ...,  0.5087, -0.7449, -0.7252],\n",
      "        [ 0.4403, -0.7647,  1.7243,  ...,  0.3978,  0.1671, -1.1830],\n",
      "        ...,\n",
      "        [-2.0407, -0.4559,  0.7629,  ..., -0.8029, -0.2862, -0.4449],\n",
      "        [ 0.7533, -0.3087,  0.0955,  ..., -0.5036, -0.1778,  0.7015],\n",
      "        [ 0.6020, -1.2712, -0.7668,  ..., -0.1817,  0.3041,  0.2943]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.5403, -0.1615, -0.1468,  ...,  0.6839,  0.2329, -0.6983],\n",
      "        [ 0.0500, -0.0963,  0.0056,  ...,  0.1050,  0.0359, -0.0044],\n",
      "        [ 0.0764, -0.1073,  0.0228,  ...,  0.1141,  0.0143, -0.0120],\n",
      "        ...,\n",
      "        [ 0.0790, -0.0703,  0.0295,  ...,  0.1804, -0.0187, -0.0201],\n",
      "        [ 0.0820, -0.0670,  0.0249,  ...,  0.1760, -0.0223, -0.0233],\n",
      "        [ 0.0830, -0.0680,  0.0241,  ...,  0.1766, -0.0245, -0.0229]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2669, -0.3856, -0.2083,  ...,  0.0617, -0.3046,  0.2342],\n",
      "        [-0.0201,  0.0248, -0.0090,  ...,  0.0774, -0.0554,  0.0560],\n",
      "        [-0.0289,  0.0023, -0.0129,  ...,  0.0730, -0.0501,  0.0630],\n",
      "        ...,\n",
      "        [-0.0465, -0.0246, -0.0232,  ...,  0.0929, -0.0650,  0.0631],\n",
      "        [-0.0456, -0.0206, -0.0324,  ...,  0.0889, -0.0653,  0.0617],\n",
      "        [-0.0479, -0.0188, -0.0317,  ...,  0.0912, -0.0660,  0.0653]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1090, -0.1099, -0.3967, -0.2730,  0.0302, -0.0417],\n",
      "        [ 0.2312, -0.1497, -0.2956, -0.1290, -0.0809, -0.0594],\n",
      "        [ 0.2528, -0.1273, -0.2566, -0.1491, -0.1514, -0.0882],\n",
      "        [ 0.0824, -0.0009, -0.3508, -0.2796,  0.0849, -0.0586],\n",
      "        [ 0.2159, -0.0925, -0.2363, -0.0944, -0.1275, -0.0779],\n",
      "        [ 0.1683, -0.0802, -0.2550, -0.1490, -0.1731, -0.0848],\n",
      "        [ 0.2316, -0.0852, -0.2918, -0.1060, -0.0779, -0.0752],\n",
      "        [ 0.2639, -0.1342, -0.2796, -0.0824, -0.1247, -0.1457],\n",
      "        [ 0.2247, -0.0912, -0.2665, -0.1340, -0.1191, -0.1055],\n",
      "        [ 0.3657, -0.1756, -0.2989, -0.0585, -0.1248, -0.0129],\n",
      "        [ 0.2568, -0.1094, -0.2971, -0.1266, -0.1206, -0.0732],\n",
      "        [ 0.1990, -0.1247, -0.2617, -0.0805, -0.1430, -0.0748],\n",
      "        [ 0.2705, -0.1206, -0.3645, -0.2200, -0.2064, -0.0506],\n",
      "        [ 0.2567, -0.1169, -0.3391, -0.1699, -0.1124, -0.0873],\n",
      "        [ 0.3172, -0.1353, -0.2571, -0.0422, -0.0618, -0.0647],\n",
      "        [ 0.2721, -0.1245, -0.2639, -0.1033, -0.1308, -0.1073],\n",
      "        [ 0.2288, -0.1159, -0.2009, -0.0746, -0.1547, -0.0420],\n",
      "        [ 0.2522, -0.1472, -0.2692, -0.1235, -0.1291, -0.0507],\n",
      "        [ 0.2147, -0.2061, -0.3000, -0.1157, -0.1138, -0.0917],\n",
      "        [ 0.0354,  0.0732, -0.3611, -0.0448,  0.0641, -0.1289],\n",
      "        [ 0.1588, -0.1414, -0.2640, -0.0429, -0.1142, -0.0070],\n",
      "        [ 0.2947, -0.0669, -0.2829, -0.1496, -0.0595, -0.0818],\n",
      "        [ 0.2308, -0.0926, -0.3023, -0.0504,  0.0014, -0.1227],\n",
      "        [ 0.2835, -0.1465, -0.2586, -0.1012, -0.1017, -0.1159],\n",
      "        [ 0.2072, -0.1387, -0.2103, -0.1107, -0.1686, -0.0426],\n",
      "        [ 0.2129, -0.1095, -0.2258, -0.1510, -0.1315, -0.0650],\n",
      "        [ 0.2526, -0.1306, -0.2753, -0.0704, -0.1368, -0.0767],\n",
      "        [ 0.1970, -0.1040, -0.2148, -0.1571, -0.1658, -0.0410],\n",
      "        [ 0.2591, -0.0968, -0.2354, -0.1499, -0.1193, -0.0550],\n",
      "        [ 0.1164, -0.1504, -0.3951, -0.2338,  0.0684,  0.0258],\n",
      "        [ 0.2084, -0.1311, -0.2334, -0.1395, -0.1806, -0.0722],\n",
      "        [ 0.2449, -0.1455, -0.2242, -0.0760, -0.0807, -0.1116]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8485]) torch.Size([2, 156952]) torch.Size([156952, 7]) torch.Size([8485])\n",
      "(tensor([[-1.5529, -0.4921, -0.6578,  ...,  0.7772, -0.6671, -1.7389],\n",
      "        [ 0.2254,  0.9116, -1.4132,  ...,  0.0854,  0.9019,  0.4324],\n",
      "        [-1.9459,  0.2051,  0.0858,  ...,  0.2602, -0.5280,  0.6790],\n",
      "        ...,\n",
      "        [ 0.3086, -0.4370,  1.4426,  ..., -0.3572,  0.0639, -0.3019],\n",
      "        [-0.6520,  0.1152, -0.7113,  ..., -0.3053, -0.5396,  0.7891],\n",
      "        [-1.3890,  0.9807, -0.7953,  ...,  1.9286, -1.5706, -0.6400]],\n",
      "       grad_fn=<AddBackward0>), tensor([[-0.0752, -0.0342,  0.0365,  ...,  0.4507,  0.2581, -0.2495],\n",
      "        [-0.0374, -0.1142, -0.0116,  ...,  0.3417,  0.1692, -0.1697],\n",
      "        [-0.0065, -0.1193, -0.0685,  ...,  0.3096,  0.1723, -0.1542],\n",
      "        ...,\n",
      "        [ 0.0688, -0.0598,  0.0099,  ...,  0.1805,  0.0015, -0.0022],\n",
      "        [ 0.0811, -0.0591,  0.0122,  ...,  0.1942, -0.0068, -0.0186],\n",
      "        [ 0.0994, -0.0740,  0.0190,  ...,  0.1953, -0.0286, -0.0254]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0511, -0.1402, -0.0371,  ...,  0.0975, -0.2176,  0.1212],\n",
      "        [ 0.0052, -0.0653, -0.0338,  ...,  0.0771, -0.1394,  0.0716],\n",
      "        [ 0.0086, -0.0616, -0.0522,  ...,  0.0827, -0.1165,  0.0480],\n",
      "        ...,\n",
      "        [-0.0359, -0.0005, -0.0051,  ...,  0.0757, -0.0798,  0.0610],\n",
      "        [-0.0312, -0.0104, -0.0142,  ...,  0.0811, -0.0859,  0.0685],\n",
      "        [-0.0504, -0.0180, -0.0131,  ...,  0.1077, -0.0746,  0.0731]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1350, -0.0664, -0.3382, -0.1043, -0.2936, -0.0853],\n",
      "        [ 0.3053, -0.2234, -0.2729, -0.1264, -0.1358, -0.0046],\n",
      "        [ 0.2239, -0.1226, -0.3322, -0.1682, -0.0404, -0.0169],\n",
      "        [ 0.2431, -0.1347, -0.2458, -0.0879, -0.1356, -0.0981],\n",
      "        [ 0.2368, -0.1176, -0.2671, -0.1125, -0.1219, -0.0971],\n",
      "        [ 0.2367, -0.1065, -0.1915, -0.0567, -0.1280, -0.1218],\n",
      "        [ 0.2098, -0.1048, -0.2382, -0.1418, -0.1151, -0.0851],\n",
      "        [ 0.1838, -0.0727, -0.2288, -0.2040, -0.1013, -0.0309],\n",
      "        [ 0.2781, -0.1481, -0.2695, -0.0974, -0.1258, -0.0581],\n",
      "        [ 0.2301, -0.1229, -0.2808, -0.1341, -0.1004, -0.0251],\n",
      "        [ 0.2617, -0.1016, -0.2451, -0.0719, -0.1878, -0.0906],\n",
      "        [ 0.2610, -0.0735, -0.2652, -0.1384, -0.1091, -0.0907],\n",
      "        [ 0.2077, -0.1054, -0.2918, -0.1486, -0.1499, -0.0640],\n",
      "        [ 0.1966, -0.1744, -0.1353, -0.1061, -0.0749, -0.1326],\n",
      "        [ 0.2334, -0.1123, -0.2049, -0.0522, -0.1250, -0.0887],\n",
      "        [ 0.2346, -0.1286, -0.3369, -0.0941, -0.0679, -0.0571],\n",
      "        [ 0.1355,  0.0032, -0.2757, -0.0622, -0.1009, -0.0850],\n",
      "        [ 0.2127, -0.1577, -0.3140, -0.2015, -0.0042, -0.0977],\n",
      "        [ 0.1992, -0.1160, -0.3068, -0.1594, -0.1020, -0.0776],\n",
      "        [ 0.2370, -0.1464, -0.2395, -0.1327, -0.0999, -0.0406],\n",
      "        [ 0.2190, -0.1364, -0.1712, -0.0656, -0.1287, -0.1055],\n",
      "        [ 0.1809, -0.0912, -0.2350, -0.1109, -0.1079, -0.0630],\n",
      "        [ 0.1672, -0.1288, -0.3086, -0.1815, -0.0810, -0.0557],\n",
      "        [ 0.1808, -0.0707, -0.3213, -0.3041, -0.0631,  0.0227],\n",
      "        [ 0.2345, -0.1287, -0.2096, -0.0506, -0.1777, -0.0308],\n",
      "        [ 0.2178, -0.0862, -0.3118, -0.1861, -0.0977, -0.0810],\n",
      "        [ 0.2010, -0.0972, -0.2872, -0.1665, -0.0545, -0.1082],\n",
      "        [ 0.2006, -0.1535, -0.2629, -0.1495, -0.1758, -0.0925],\n",
      "        [ 0.1953, -0.1405, -0.3729, -0.2307,  0.0808, -0.0407],\n",
      "        [ 0.2852, -0.1276, -0.3112, -0.1565, -0.0834, -0.0653],\n",
      "        [ 0.2241, -0.1127, -0.2786, -0.1912, -0.1684, -0.0487],\n",
      "        [ 0.2156, -0.1100, -0.2529, -0.0784, -0.0872, -0.0467]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7717]) torch.Size([2, 141490]) torch.Size([141490, 7]) torch.Size([7717])\n",
      "(tensor([[-0.9656, -0.6978,  1.0583,  ...,  0.3487, -2.1203,  0.8971],\n",
      "        [-0.8369, -0.6817,  0.5494,  ..., -0.6787,  1.1522, -0.0143],\n",
      "        [-0.6209,  0.3915, -1.9239,  ...,  1.8124,  0.2467,  0.1430],\n",
      "        ...,\n",
      "        [-1.4541,  1.0747, -1.2644,  ...,  1.2546, -1.2019,  0.3425],\n",
      "        [-0.7453, -1.1947, -0.0985,  ...,  0.1256, -0.5357, -0.1792],\n",
      "        [ 0.2538,  0.7777, -0.2162,  ...,  0.8938, -1.0476, -0.0611]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0671, -0.0328,  0.0240,  ...,  0.1701,  0.0518, -0.0356],\n",
      "        [ 0.0696, -0.0434,  0.0228,  ...,  0.2140,  0.0069, -0.0280],\n",
      "        [ 0.1820, -0.0606,  0.0043,  ...,  0.2121,  0.1168, -0.2263],\n",
      "        ...,\n",
      "        [ 0.0349, -0.0639, -0.0161,  ...,  0.1691,  0.0024,  0.0030],\n",
      "        [ 0.0102, -0.0831, -0.0311,  ...,  0.1417,  0.0023,  0.0064],\n",
      "        [ 0.0267, -0.0775, -0.0171,  ...,  0.1442,  0.0149,  0.0028]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0286, -0.0280,  0.0082,  ...,  0.0614, -0.0687,  0.0316],\n",
      "        [-0.0579, -0.0262,  0.0036,  ...,  0.1131, -0.0722,  0.0560],\n",
      "        [ 0.1104, -0.0503, -0.0208,  ...,  0.0070, -0.0485,  0.0681],\n",
      "        ...,\n",
      "        [-0.0470,  0.0177, -0.0272,  ...,  0.0687, -0.0840,  0.0286],\n",
      "        [-0.0712,  0.0417, -0.0256,  ...,  0.0607, -0.0729,  0.0244],\n",
      "        [-0.0498,  0.0272, -0.0151,  ...,  0.0722, -0.0772,  0.0208]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2240, -0.1050, -0.2840, -0.0942, -0.0512, -0.0814],\n",
      "        [ 0.2223, -0.1618, -0.2967, -0.1778, -0.1589, -0.0288],\n",
      "        [ 0.2107, -0.1019, -0.2439, -0.0346, -0.1000, -0.0476],\n",
      "        [ 0.2284, -0.0803, -0.1849, -0.0045, -0.1886, -0.1628],\n",
      "        [ 0.2071, -0.2175, -0.3318, -0.1106, -0.1724, -0.0516],\n",
      "        [ 0.0979, -0.0577, -0.2554, -0.2630,  0.0063, -0.0265],\n",
      "        [ 0.2082, -0.1409, -0.2427, -0.1639, -0.1556, -0.1073],\n",
      "        [ 0.2215, -0.1278, -0.2673, -0.1354, -0.0633, -0.0313],\n",
      "        [ 0.2237, -0.1510, -0.3243, -0.1201, -0.1611, -0.0374],\n",
      "        [ 0.2845, -0.1338, -0.2891, -0.1109, -0.0888, -0.0533],\n",
      "        [ 0.1998, -0.1349, -0.3182, -0.1227, -0.1074, -0.1355],\n",
      "        [ 0.3515, -0.1656, -0.3645, -0.1603, -0.0868,  0.0237],\n",
      "        [ 0.2225, -0.0931, -0.2559, -0.0759, -0.1332,  0.0239],\n",
      "        [ 0.2366, -0.0801, -0.3203, -0.1104, -0.0699, -0.1235],\n",
      "        [ 0.2798, -0.1749, -0.3036, -0.0482, -0.0977,  0.0101],\n",
      "        [ 0.2285, -0.1324, -0.2856, -0.1673, -0.1359, -0.0491],\n",
      "        [ 0.2298, -0.1424, -0.2800, -0.1067, -0.0597, -0.0828],\n",
      "        [ 0.2373, -0.1750, -0.2790, -0.0472, -0.0967, -0.0605],\n",
      "        [ 0.2923, -0.1539, -0.2961, -0.1244, -0.1488, -0.0329],\n",
      "        [ 0.1992, -0.1692, -0.3298, -0.0345, -0.1275,  0.0189],\n",
      "        [ 0.2565, -0.1149, -0.2481, -0.0911, -0.1275, -0.0714],\n",
      "        [ 0.2338, -0.1940, -0.2187, -0.0987, -0.1073, -0.0276],\n",
      "        [ 0.2631, -0.1822, -0.2679, -0.1207, -0.1333, -0.0594],\n",
      "        [ 0.2131, -0.0894, -0.1834, -0.1336, -0.1299, -0.0330],\n",
      "        [ 0.1655, -0.0961, -0.2363, -0.1154, -0.1166, -0.1053],\n",
      "        [ 0.2894, -0.1128, -0.2429, -0.1553, -0.1901, -0.1601],\n",
      "        [ 0.2028, -0.0674, -0.3245, -0.1074, -0.0697, -0.0514],\n",
      "        [ 0.2978, -0.0609, -0.2664, -0.1336, -0.2176, -0.1207],\n",
      "        [ 0.2647, -0.1374, -0.2941, -0.1341, -0.0964, -0.1107],\n",
      "        [ 0.2260, -0.1282, -0.2797, -0.0947, -0.1275, -0.0464],\n",
      "        [ 0.1887, -0.2201, -0.2704, -0.0169, -0.1632, -0.0237],\n",
      "        [ 0.1906, -0.1373, -0.2916, -0.1065, -0.0974, -0.0029]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8395]) torch.Size([2, 158162]) torch.Size([158162, 7]) torch.Size([8395])\n",
      "(tensor([[-0.4044, -1.1127, -1.2551,  ...,  1.4607,  0.1776, -1.7690],\n",
      "        [-0.9166,  1.4873,  0.0159,  ...,  1.8984,  0.7956, -2.0374],\n",
      "        [ 0.2456, -0.5118, -1.7652,  ...,  0.8324,  0.1391,  0.3124],\n",
      "        ...,\n",
      "        [-3.5897, -0.3059, -1.8057,  ...,  0.3457,  1.2914, -1.1610],\n",
      "        [-0.8385,  1.9116, -0.0462,  ...,  0.1178, -0.4469, -0.0482],\n",
      "        [ 2.0973,  0.3157,  0.2164,  ..., -0.1091, -0.8375, -2.1671]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0765, -0.0312,  0.0481,  ...,  0.1631,  0.1197, -0.0822],\n",
      "        [ 0.0756, -0.0580,  0.0386,  ...,  0.1591, -0.0018, -0.0215],\n",
      "        [ 0.2126,  0.0276,  0.0272,  ...,  0.2844,  0.1541, -0.1564],\n",
      "        ...,\n",
      "        [ 0.0798, -0.0948,  0.0172,  ...,  0.1644, -0.0027, -0.0195],\n",
      "        [ 0.0799, -0.0947,  0.0172,  ...,  0.1644, -0.0028, -0.0195],\n",
      "        [ 0.0868, -0.0840,  0.0267,  ...,  0.1749, -0.0223, -0.0347]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0382, -0.0326,  0.0025,  ...,  0.0607, -0.0396,  0.0436],\n",
      "        [-0.0481, -0.0037, -0.0244,  ...,  0.0923, -0.0656,  0.0719],\n",
      "        [ 0.2077, -0.1716,  0.0055,  ...,  0.1426, -0.0870,  0.0076],\n",
      "        ...,\n",
      "        [-0.0385,  0.0012, -0.0180,  ...,  0.0858, -0.0579,  0.0875],\n",
      "        [-0.0386,  0.0012, -0.0180,  ...,  0.0859, -0.0579,  0.0875],\n",
      "        [-0.0506, -0.0203, -0.0222,  ...,  0.0970, -0.0719,  0.0844]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2401, -0.1915, -0.2566, -0.1548, -0.1571, -0.0764],\n",
      "        [ 0.2337, -0.1081, -0.2911, -0.0809, -0.1289, -0.0232],\n",
      "        [ 0.1974, -0.0751, -0.2449, -0.0469, -0.0718, -0.0884],\n",
      "        [ 0.2342, -0.1425, -0.2581, -0.1208, -0.0817, -0.0932],\n",
      "        [ 0.2045, -0.0912, -0.2665, -0.1313, -0.1428, -0.0914],\n",
      "        [ 0.2312, -0.1827, -0.1692, -0.1936, -0.1831, -0.0116],\n",
      "        [ 0.2647, -0.1593, -0.2178, -0.0817, -0.1417, -0.0951],\n",
      "        [ 0.2340, -0.0949, -0.3503, -0.1302, -0.0498, -0.0020],\n",
      "        [ 0.2012, -0.1122, -0.3160, -0.1550, -0.0322, -0.0835],\n",
      "        [ 0.2880, -0.1798, -0.2909, -0.1465, -0.1570, -0.0034],\n",
      "        [ 0.1926, -0.1258, -0.3687, -0.2305,  0.0311, -0.0895],\n",
      "        [ 0.2779, -0.2095, -0.3385, -0.0901, -0.1380, -0.0789],\n",
      "        [ 0.2349, -0.0650, -0.3008, -0.1264, -0.1363, -0.0842],\n",
      "        [ 0.1740,  0.0673, -0.3557, -0.0347, -0.1466, -0.2215],\n",
      "        [ 0.2289, -0.0522, -0.2256, -0.1530, -0.0575, -0.0844],\n",
      "        [ 0.2015, -0.1636, -0.2338, -0.1804, -0.1559, -0.0350],\n",
      "        [ 0.1307, -0.0428, -0.2979, -0.1354, -0.1037, -0.0259],\n",
      "        [ 0.2468, -0.1898, -0.2928, -0.0983, -0.1236, -0.0774],\n",
      "        [ 0.2505, -0.1257, -0.2935, -0.0760, -0.1058, -0.0600],\n",
      "        [ 0.2373, -0.1592, -0.2827, -0.0733, -0.0733, -0.0787],\n",
      "        [ 0.2279, -0.1444, -0.2721, -0.0775, -0.1000, -0.1275],\n",
      "        [ 0.2493, -0.1446, -0.2783, -0.1802, -0.1636, -0.0272],\n",
      "        [ 0.2645, -0.1945, -0.3282, -0.1234, -0.1836, -0.0876],\n",
      "        [ 0.2482, -0.0938, -0.2469, -0.1114, -0.1649, -0.0913],\n",
      "        [ 0.1736, -0.1302, -0.2339, -0.0840, -0.1331, -0.0301],\n",
      "        [ 0.2070, -0.1470, -0.2552, -0.1088, -0.1463, -0.0511],\n",
      "        [ 0.2113, -0.0756, -0.2109, -0.0851, -0.1555, -0.0967],\n",
      "        [ 0.1998, -0.1484, -0.2469, -0.0896, -0.1048, -0.0608],\n",
      "        [ 0.2079, -0.1038, -0.2406, -0.0957, -0.0966, -0.0786],\n",
      "        [ 0.2725, -0.1046, -0.2636, -0.1299, -0.1168, -0.1051],\n",
      "        [ 0.1159, -0.1612, -0.3229, -0.2552,  0.0029, -0.0236],\n",
      "        [ 0.2149, -0.1771, -0.2406, -0.1028, -0.1255, -0.0831]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7734]) torch.Size([2, 153516]) torch.Size([153516, 7]) torch.Size([7734])\n",
      "(tensor([[-9.6450e-01, -1.0704e+00,  6.2469e-01,  ...,  5.3652e-01,\n",
      "          2.2557e-01,  8.1553e-01],\n",
      "        [ 1.4426e+00, -1.1109e+00,  6.5334e-01,  ...,  1.9930e-02,\n",
      "          6.2821e-01, -2.0645e-01],\n",
      "        [-1.4409e+00,  2.0271e+00,  1.0095e+00,  ..., -3.1720e-01,\n",
      "         -6.0210e-02, -6.0218e-01],\n",
      "        ...,\n",
      "        [-1.9196e-01,  4.0904e-01,  1.2075e+00,  ...,  6.3632e-01,\n",
      "         -7.7450e-01, -6.9721e-01],\n",
      "        [ 1.1283e+00, -2.6141e-01,  1.9837e+00,  ...,  1.0867e+00,\n",
      "         -5.3703e-01,  7.1467e-01],\n",
      "        [ 1.3368e+00, -1.0579e+00,  5.6877e-04,  ..., -4.8273e-02,\n",
      "         -9.7076e-02, -5.5123e-01]], grad_fn=<AddBackward0>), tensor([[ 0.0470, -0.0345,  0.0488,  ...,  0.1748,  0.0056, -0.0212],\n",
      "        [ 0.0536, -0.0452,  0.0445,  ...,  0.1802,  0.0125, -0.0237],\n",
      "        [ 0.0472, -0.0581,  0.0398,  ...,  0.1275,  0.0499, -0.0500],\n",
      "        ...,\n",
      "        [ 0.0948, -0.0739,  0.0259,  ...,  0.1901, -0.0334, -0.0334],\n",
      "        [ 0.0936, -0.0787,  0.0109,  ...,  0.1934, -0.0387, -0.0319],\n",
      "        [ 0.0927, -0.0767,  0.0121,  ...,  0.1923, -0.0406, -0.0330]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0308, -0.0290,  0.0050,  ...,  0.0688, -0.0504,  0.0285],\n",
      "        [-0.0425, -0.0250, -0.0006,  ...,  0.0718, -0.0657,  0.0333],\n",
      "        [-0.0196, -0.0147, -0.0036,  ...,  0.0446, -0.0310,  0.0601],\n",
      "        ...,\n",
      "        [-0.0538, -0.0240, -0.0244,  ...,  0.1033, -0.0713,  0.0583],\n",
      "        [-0.0610, -0.0158, -0.0046,  ...,  0.1028, -0.0760,  0.0674],\n",
      "        [-0.0562, -0.0191, -0.0070,  ...,  0.1034, -0.0767,  0.0574]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2193, -0.1403, -0.1786, -0.0437, -0.1512, -0.0809],\n",
      "        [ 0.1964, -0.1084, -0.2419, -0.0766, -0.1553, -0.1032],\n",
      "        [ 0.1734, -0.0603, -0.2819, -0.1647, -0.0924, -0.0709],\n",
      "        [ 0.1683, -0.1460, -0.2670, -0.1217, -0.1816, -0.0910],\n",
      "        [ 0.2125, -0.1078, -0.2628, -0.1694, -0.1229, -0.0764],\n",
      "        [ 0.2292, -0.1172, -0.2741, -0.1476, -0.0758,  0.0069],\n",
      "        [ 0.2112, -0.1921, -0.3508, -0.0939, -0.0936, -0.1316],\n",
      "        [ 0.2138, -0.1869, -0.2763, -0.0679, -0.1099, -0.1551],\n",
      "        [ 0.2822, -0.1936, -0.2841, -0.0880, -0.0757, -0.0507],\n",
      "        [ 0.3223, -0.1311, -0.2522, -0.0814, -0.1485, -0.1215],\n",
      "        [ 0.0974,  0.0339, -0.1729, -0.0211, -0.0891, -0.1671],\n",
      "        [ 0.2241, -0.1378, -0.3544, -0.2065, -0.0101, -0.0357],\n",
      "        [ 0.2418, -0.0684, -0.2814, -0.1077, -0.0406, -0.1048],\n",
      "        [ 0.2574, -0.1357, -0.2723, -0.1040, -0.0869, -0.0936],\n",
      "        [ 0.1966,  0.0007, -0.2776, -0.1620, -0.0474, -0.1060],\n",
      "        [ 0.2598, -0.0890, -0.2989, -0.1446, -0.1398, -0.0053],\n",
      "        [ 0.2120, -0.1229, -0.1900, -0.0824, -0.1092, -0.0944],\n",
      "        [ 0.1892, -0.1049, -0.2241, -0.0779, -0.1557, -0.0406],\n",
      "        [ 0.2595, -0.1457, -0.2718, -0.1041, -0.1022, -0.0759],\n",
      "        [ 0.2384, -0.1256, -0.2437, -0.0732, -0.1083, -0.0387],\n",
      "        [ 0.1199, -0.1946, -0.3171, -0.1625, -0.1133, -0.0813],\n",
      "        [ 0.2198, -0.2382, -0.3075, -0.1609, -0.0661, -0.0509],\n",
      "        [ 0.1983,  0.0065, -0.2345, -0.1300, -0.1090, -0.0186],\n",
      "        [ 0.1938, -0.1154, -0.2262, -0.0761, -0.1105, -0.0980],\n",
      "        [ 0.2355, -0.1238, -0.2274, -0.1382, -0.1827, -0.0777],\n",
      "        [ 0.2345, -0.1501, -0.2343, -0.1098, -0.1559, -0.0522],\n",
      "        [ 0.2497, -0.1210, -0.2843, -0.1279, -0.1233, -0.0411],\n",
      "        [ 0.2917, -0.1869, -0.2057, -0.0700, -0.1101, -0.0655],\n",
      "        [ 0.1855, -0.1018, -0.2670, -0.0994, -0.1107, -0.0273],\n",
      "        [ 0.2754, -0.1323, -0.2797, -0.0604, -0.0915, -0.0642],\n",
      "        [ 0.1675, -0.0923, -0.3055, -0.1561, -0.0851,  0.0041],\n",
      "        [ 0.1134, -0.1952, -0.3940, -0.3359,  0.0611, -0.0718]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8146]) torch.Size([2, 139416]) torch.Size([139416, 7]) torch.Size([8146])\n",
      "(tensor([[-1.5217, -0.1949, -0.2248,  ...,  0.5040,  0.4198, -1.5640],\n",
      "        [ 0.3344,  1.0374,  2.1157,  ..., -0.3382, -0.5571,  0.6713],\n",
      "        [-1.1746, -1.7143,  0.3139,  ..., -0.4171,  0.0961, -0.1741],\n",
      "        ...,\n",
      "        [ 0.5304, -1.4259,  0.4886,  ..., -1.7823,  0.5337,  1.2447],\n",
      "        [-0.4097,  1.1480,  0.9867,  ...,  0.1178,  1.6753, -0.2258],\n",
      "        [-0.6499,  0.7824,  2.1862,  ...,  1.9148,  0.4083,  1.9483]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.5022, -0.2239, -0.1034,  ...,  0.4535,  0.6192, -0.9844],\n",
      "        [ 0.0592, -0.0721,  0.0413,  ...,  0.1312,  0.0310, -0.0158],\n",
      "        [ 0.0383, -0.0625,  0.0410,  ...,  0.1457,  0.1207, -0.0748],\n",
      "        ...,\n",
      "        [ 0.1076, -0.0694,  0.0337,  ...,  0.1973, -0.0299, -0.0364],\n",
      "        [ 0.1078, -0.0691,  0.0338,  ...,  0.1978, -0.0302, -0.0361],\n",
      "        [ 0.1007, -0.0656,  0.0305,  ...,  0.1952, -0.0208, -0.0357]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.4705, -0.5403, -0.0580,  ..., -0.0620, -0.3512,  0.3717],\n",
      "        [-0.0229,  0.0099,  0.0027,  ...,  0.0786, -0.0616,  0.0614],\n",
      "        [ 0.0309, -0.0110,  0.0019,  ...,  0.0275, -0.0308,  0.0473],\n",
      "        ...,\n",
      "        [-0.0592, -0.0352, -0.0100,  ...,  0.1179, -0.0842,  0.0858],\n",
      "        [-0.0596, -0.0353, -0.0103,  ...,  0.1181, -0.0846,  0.0852],\n",
      "        [-0.0578, -0.0320, -0.0113,  ...,  0.1166, -0.0826,  0.0871]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.3090, -0.1336, -0.2461, -0.0874, -0.1157, -0.0907],\n",
      "        [ 0.2630, -0.1171, -0.2794, -0.1050, -0.1313, -0.0225],\n",
      "        [ 0.2285, -0.1600, -0.3271, -0.1362, -0.0743, -0.0835],\n",
      "        [ 0.1478, -0.0407, -0.3238, -0.1297, -0.0519, -0.0214],\n",
      "        [ 0.2148, -0.0593, -0.1974, -0.1045, -0.0997, -0.0559],\n",
      "        [ 0.2292, -0.1564, -0.2577, -0.1199, -0.0880, -0.0947],\n",
      "        [ 0.1074, -0.0830, -0.2476, -0.1488, -0.0360, -0.0931],\n",
      "        [ 0.2020, -0.0279, -0.3841, -0.2555, -0.0420, -0.0380],\n",
      "        [ 0.1892, -0.1304, -0.2518, -0.0917, -0.1075, -0.0748],\n",
      "        [ 0.2423, -0.0956, -0.2306, -0.1042, -0.0998, -0.0389],\n",
      "        [ 0.2531, -0.0422, -0.2111, -0.0153, -0.2990, -0.0896],\n",
      "        [ 0.2429, -0.1634, -0.3207, -0.0934, -0.1508, -0.0438],\n",
      "        [ 0.3723, -0.1285, -0.3365, -0.1799, -0.1067, -0.0105],\n",
      "        [ 0.2404, -0.1334, -0.3154, -0.1103, -0.0939, -0.0334],\n",
      "        [ 0.2377, -0.1228, -0.3241, -0.1979, -0.1109, -0.0549],\n",
      "        [ 0.1781, -0.1671, -0.2889, -0.1531, -0.1115, -0.0748],\n",
      "        [ 0.1934, -0.1204, -0.2414, -0.1015, -0.1287, -0.0665],\n",
      "        [ 0.2124, -0.1796, -0.2760, -0.1237, -0.1761, -0.0627],\n",
      "        [ 0.2174, -0.1682, -0.2564, -0.1514, -0.1243, -0.0716],\n",
      "        [ 0.2680, -0.1415, -0.2951, -0.1000, -0.1210, -0.0453],\n",
      "        [ 0.2278, -0.1187, -0.2517, -0.1366, -0.1597, -0.0414],\n",
      "        [ 0.2087, -0.0944, -0.2554, -0.1461, -0.1799, -0.0308],\n",
      "        [ 0.1883, -0.1027, -0.3056, -0.1837, -0.0871, -0.0870],\n",
      "        [ 0.1461, -0.0653, -0.2756, -0.1705, -0.0306, -0.0717],\n",
      "        [ 0.1338, -0.0248, -0.2542, -0.2288,  0.0472, -0.0360],\n",
      "        [ 0.0034, -0.0762, -0.5146, -0.6443, -0.0330, -0.1673],\n",
      "        [ 0.2553, -0.0790, -0.3069, -0.1364, -0.0581, -0.0932],\n",
      "        [ 0.2094, -0.0967, -0.3556, -0.1805, -0.0398, -0.0736],\n",
      "        [ 0.2352, -0.1268, -0.1954,  0.0086, -0.0854, -0.1123],\n",
      "        [ 0.1908, -0.1174, -0.2669, -0.1274, -0.0760, -0.0753],\n",
      "        [ 0.2470, -0.1574, -0.3479, -0.1345, -0.0765, -0.0582],\n",
      "        [ 0.2321, -0.0825, -0.2545, -0.1244, -0.1585, -0.0962]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7462]) torch.Size([2, 125904]) torch.Size([125904, 7]) torch.Size([7462])\n",
      "(tensor([[ 0.1263, -0.9974, -1.4044,  ..., -0.0762,  0.0835, -0.3469],\n",
      "        [ 0.3640,  0.9945,  1.3196,  ...,  0.6431,  0.3100, -0.4349],\n",
      "        [ 1.2789,  0.1630, -1.9626,  ...,  0.2843, -0.2003, -1.7720],\n",
      "        ...,\n",
      "        [ 1.2880, -0.6206,  0.7186,  ..., -1.6950, -0.7107,  0.6444],\n",
      "        [-1.2059,  0.7671, -1.0417,  ..., -1.1923,  0.1604,  1.3164],\n",
      "        [ 0.4492, -0.0023, -0.9273,  ..., -0.2186, -0.6449, -0.2548]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.2862, -0.0956, -0.0138,  ...,  0.3620,  0.0214, -0.1396],\n",
      "        [ 0.2051, -0.0358, -0.0109,  ...,  0.3040,  0.0197, -0.0897],\n",
      "        [ 0.0974, -0.0801,  0.0392,  ...,  0.0943,  0.0392, -0.0470],\n",
      "        ...,\n",
      "        [ 0.0566, -0.0720,  0.0444,  ...,  0.1188,  0.0387, -0.0196],\n",
      "        [ 0.0865, -0.0627,  0.0282,  ...,  0.1799, -0.0108, -0.0254],\n",
      "        [ 0.0500, -0.0634,  0.0411,  ...,  0.1451,  0.0376, -0.0372]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1952, -0.1649, -0.1395,  ...,  0.0947, -0.1515, -0.0185],\n",
      "        [ 0.1140, -0.1272, -0.0957,  ...,  0.1194, -0.0991, -0.0068],\n",
      "        [ 0.0722, -0.0317,  0.0009,  ...,  0.0609, -0.0665, -0.0239],\n",
      "        ...,\n",
      "        [-0.0440,  0.0053,  0.0050,  ...,  0.0838, -0.0511,  0.0810],\n",
      "        [-0.0437, -0.0136, -0.0157,  ...,  0.1007, -0.0731,  0.0760],\n",
      "        [-0.0223, -0.0085,  0.0067,  ...,  0.0712, -0.0542,  0.0597]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1672, -0.1330, -0.2839, -0.1776, -0.1209, -0.0333],\n",
      "        [ 0.1793, -0.1263, -0.1980, -0.1402, -0.1429, -0.0517],\n",
      "        [ 0.2622, -0.1255, -0.2789, -0.0838, -0.0924, -0.0301],\n",
      "        [ 0.1633, -0.1160, -0.2819, -0.1748, -0.1242, -0.1168],\n",
      "        [ 0.1897, -0.0976, -0.2236, -0.1109, -0.1415, -0.0715],\n",
      "        [ 0.2479, -0.1672, -0.2563, -0.1064, -0.1110, -0.0322],\n",
      "        [ 0.2320, -0.1309, -0.2073, -0.1141, -0.1196, -0.1151],\n",
      "        [ 0.2578, -0.1538, -0.2621, -0.0781, -0.1636, -0.0693],\n",
      "        [ 0.2686, -0.0729, -0.2741,  0.0317, -0.1330, -0.0099],\n",
      "        [ 0.2067, -0.1079, -0.2503, -0.1522, -0.1219, -0.0387],\n",
      "        [ 0.2412, -0.1007, -0.2348, -0.1250, -0.1371, -0.0240],\n",
      "        [ 0.2115, -0.1726, -0.2861, -0.1559, -0.1253, -0.0910],\n",
      "        [ 0.3533, -0.1259, -0.2981, -0.1056, -0.1503, -0.0028],\n",
      "        [ 0.2564, -0.1345, -0.2230, -0.1181, -0.0371, -0.1386],\n",
      "        [ 0.2254, -0.1005, -0.5076, -0.1951, -0.1071,  0.1210],\n",
      "        [ 0.1915, -0.1979, -0.3863, -0.1943,  0.0114, -0.0650],\n",
      "        [ 0.0427, -0.0075, -0.4067, -0.3519,  0.0891, -0.1610],\n",
      "        [ 0.2122, -0.1168, -0.2464, -0.1497, -0.0900, -0.0418],\n",
      "        [ 0.2925, -0.1230, -0.2885, -0.1777, -0.1143, -0.0469],\n",
      "        [ 0.2263, -0.1236, -0.2828, -0.1491, -0.1267, -0.0774],\n",
      "        [ 0.2713, -0.1882, -0.2658, -0.0958, -0.1236, -0.0300],\n",
      "        [ 0.2241, -0.0789, -0.2260, -0.1297, -0.0845, -0.1004],\n",
      "        [ 0.1710, -0.1128, -0.2420, -0.0964, -0.1404, -0.0535],\n",
      "        [ 0.1954, -0.1636, -0.2112, -0.0473, -0.1627, -0.0867],\n",
      "        [ 0.2469, -0.1891, -0.2643, -0.0955, -0.1206, -0.0902],\n",
      "        [ 0.2815, -0.1100, -0.3295, -0.0375, -0.1206, -0.1193],\n",
      "        [ 0.2365, -0.1179, -0.2643, -0.1586, -0.1416, -0.0651],\n",
      "        [ 0.1802, -0.1125, -0.2972, -0.1721, -0.0683, -0.1046],\n",
      "        [ 0.1686, -0.0941, -0.2500, -0.0758, -0.1306, -0.0682],\n",
      "        [ 0.2383, -0.1947, -0.2346, -0.0887, -0.1335, -0.0965],\n",
      "        [ 0.3017, -0.1151, -0.2806, -0.0294, -0.0628, -0.0457],\n",
      "        [ 0.2488, -0.0642, -0.0978,  0.0156, -0.2549, -0.1335]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7655]) torch.Size([2, 118856]) torch.Size([118856, 7]) torch.Size([7655])\n",
      "(tensor([[-0.0270,  0.4427, -0.8772,  ..., -0.9766,  1.9740,  0.2408],\n",
      "        [ 1.6771,  0.9469, -0.0381,  ...,  0.2225, -0.2939,  0.1682],\n",
      "        [-0.2166, -0.1950, -1.2961,  ..., -0.1185,  0.1031,  0.4522],\n",
      "        ...,\n",
      "        [ 0.1600, -1.2241, -0.6806,  ...,  0.8538,  0.1572,  0.7453],\n",
      "        [ 0.3137,  0.6213,  0.3099,  ...,  0.1958, -0.3000, -0.1558],\n",
      "        [-0.4568, -1.0530, -0.3995,  ...,  0.2511, -2.3565, -0.2529]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0278, -0.0275,  0.0560,  ...,  0.1743,  0.0074, -0.0227],\n",
      "        [ 0.0179, -0.0318,  0.0429,  ...,  0.1759,  0.0267, -0.0210],\n",
      "        [ 0.0070, -0.0444,  0.0566,  ...,  0.1735,  0.0621, -0.0579],\n",
      "        ...,\n",
      "        [ 0.0737, -0.0595,  0.0407,  ...,  0.1604, -0.0083, -0.0302],\n",
      "        [ 0.0398, -0.0602,  0.0508,  ...,  0.1149,  0.0522, -0.0192],\n",
      "        [ 0.0642, -0.0647,  0.0435,  ...,  0.1513,  0.0128, -0.0305]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0297, -0.0382, -0.0419,  ...,  0.0760, -0.0416,  0.0280],\n",
      "        [-0.0315, -0.0329, -0.0335,  ...,  0.0816, -0.0327,  0.0102],\n",
      "        [-0.0237, -0.0300, -0.0605,  ...,  0.0459, -0.0444, -0.0060],\n",
      "        ...,\n",
      "        [-0.0400, -0.0152, -0.0223,  ...,  0.0929, -0.0496,  0.0505],\n",
      "        [-0.0330, -0.0015,  0.0227,  ...,  0.0597, -0.0604,  0.0555],\n",
      "        [-0.0529,  0.0032, -0.0206,  ...,  0.0847, -0.0605,  0.0771]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1522, -0.1497, -0.1923, -0.1434, -0.1408, -0.1341],\n",
      "        [ 0.2345, -0.1863, -0.2472, -0.1068, -0.1255, -0.0878],\n",
      "        [ 0.2501, -0.1542, -0.3239, -0.0739, -0.0280, -0.1805],\n",
      "        [ 0.2611, -0.1241, -0.2493, -0.1208, -0.1250, -0.0631],\n",
      "        [ 0.2849, -0.0840, -0.2961, -0.0966, -0.1072, -0.0526],\n",
      "        [ 0.2154, -0.1032, -0.2260, -0.0641, -0.1206, -0.0461],\n",
      "        [ 0.1862, -0.0838, -0.2491, -0.1422, -0.0741, -0.0891],\n",
      "        [ 0.1809, -0.0629, -0.3444, -0.2222, -0.1371, -0.1090],\n",
      "        [ 0.2333, -0.1095, -0.1269,  0.0693, -0.1760, -0.0283],\n",
      "        [ 0.2440, -0.1054, -0.2235, -0.1275, -0.0922, -0.0942],\n",
      "        [ 0.2505, -0.2048, -0.2968, -0.1160, -0.1109, -0.0252],\n",
      "        [ 0.2589, -0.1801, -0.3248, -0.0383, -0.0476, -0.0499],\n",
      "        [ 0.2679, -0.1331, -0.3064, -0.1392,  0.0362, -0.0211],\n",
      "        [ 0.3370, -0.1616, -0.3022, -0.1333, -0.1305, -0.0590],\n",
      "        [ 0.2233, -0.1424, -0.2794, -0.1427, -0.1320, -0.0546],\n",
      "        [ 0.2006, -0.2306, -0.2349, -0.0561, -0.0668, -0.1640],\n",
      "        [ 0.1993, -0.0696, -0.2621, -0.1508, -0.1211, -0.0695],\n",
      "        [ 0.2238, -0.1481, -0.2644, -0.1720, -0.1522, -0.0525],\n",
      "        [ 0.1195, -0.0226, -0.2192, -0.1554, -0.1822, -0.0613],\n",
      "        [ 0.2986, -0.1636, -0.2952, -0.0527, -0.1147, -0.0725],\n",
      "        [ 0.2386, -0.0920, -0.2523, -0.1230, -0.1060, -0.0629],\n",
      "        [ 0.2625, -0.1418, -0.2945, -0.1490, -0.1323, -0.0533],\n",
      "        [ 0.2623, -0.1495, -0.2653, -0.1229, -0.1181, -0.0345],\n",
      "        [ 0.2543, -0.1770, -0.2614, -0.1484, -0.1369, -0.1094],\n",
      "        [ 0.2292, -0.1330, -0.2798, -0.1512, -0.0869, -0.0859],\n",
      "        [ 0.2375, -0.2196, -0.2212,  0.0012, -0.1409, -0.0661],\n",
      "        [ 0.2211,  0.0639, -0.2268, -0.1278, -0.0371, -0.0801],\n",
      "        [ 0.1368, -0.1393, -0.4037, -0.2858,  0.0496, -0.0244],\n",
      "        [ 0.1715, -0.0484, -0.2303, -0.1698, -0.1735, -0.1087],\n",
      "        [ 0.2724, -0.1830, -0.3563, -0.1412, -0.1322, -0.0526],\n",
      "        [ 0.1705, -0.0554, -0.2161, -0.0519, -0.1009, -0.1025],\n",
      "        [ 0.2308, -0.1261, -0.2100, -0.0919, -0.1068, -0.1157]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([6992]) torch.Size([2, 135198]) torch.Size([135198, 7]) torch.Size([6992])\n",
      "(tensor([[ 0.2172,  0.4842, -0.4348,  ...,  0.6143, -0.8650,  0.4125],\n",
      "        [-0.4217,  0.3550, -0.9155,  ...,  1.9071,  1.2346, -1.4670],\n",
      "        [ 1.1964, -0.8616,  0.2208,  ...,  0.2967, -0.1618, -0.3959],\n",
      "        ...,\n",
      "        [ 0.3333, -0.1749, -0.2669,  ...,  0.4046, -1.1051, -1.4484],\n",
      "        [ 0.0298,  1.7651,  0.1156,  ..., -0.0112, -0.1261,  0.3190],\n",
      "        [ 0.8073, -1.1621,  0.9145,  ...,  1.2421, -0.5335,  1.5001]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0897, -0.1153,  0.0117,  ...,  0.0884,  0.0250, -0.0318],\n",
      "        [ 0.5751, -0.0346, -0.0704,  ...,  0.7454,  0.0832, -0.3764],\n",
      "        [ 0.3091, -0.1648, -0.0793,  ...,  0.2384,  0.0954, -0.2436],\n",
      "        ...,\n",
      "        [ 0.0659, -0.0818,  0.0198,  ...,  0.1397,  0.0169, -0.0216],\n",
      "        [ 0.0700, -0.0760,  0.0099,  ...,  0.1664,  0.0123, -0.0132],\n",
      "        [ 0.0893, -0.0812,  0.0219,  ...,  0.1735,  0.0031, -0.0265]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0593,  0.0036, -0.0119,  ...,  0.0820, -0.0235,  0.0292],\n",
      "        [ 0.3736, -0.3982, -0.4153,  ...,  0.0676, -0.2735,  0.1236],\n",
      "        [ 0.1552, -0.0666, -0.0302,  ..., -0.0298, -0.1796,  0.0104],\n",
      "        ...,\n",
      "        [-0.0134,  0.0015, -0.0071,  ...,  0.0761, -0.0478,  0.0534],\n",
      "        [-0.0373,  0.0097, -0.0007,  ...,  0.0896, -0.0781,  0.0797],\n",
      "        [-0.0334, -0.0070,  0.0017,  ...,  0.0955, -0.0756,  0.0904]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2482, -0.1552, -0.2890, -0.0972, -0.0710, -0.1195],\n",
      "        [ 0.2308, -0.1067, -0.2441, -0.0785, -0.0897, -0.0334],\n",
      "        [ 0.3258, -0.1873, -0.3228, -0.1432, -0.1370, -0.0252],\n",
      "        [ 0.1916, -0.0925, -0.2238, -0.0747, -0.1540, -0.0471],\n",
      "        [ 0.1715, -0.1886, -0.2316,  0.0345, -0.2344,  0.0738],\n",
      "        [ 0.2014, -0.1816, -0.3126, -0.1839, -0.0218, -0.0235],\n",
      "        [ 0.1898, -0.1214, -0.2753, -0.2356, -0.0728, -0.0214],\n",
      "        [ 0.2620, -0.0914, -0.2756, -0.0944, -0.1258, -0.0584],\n",
      "        [ 0.1749, -0.1169, -0.2671, -0.1614, -0.1447, -0.0977],\n",
      "        [ 0.2219, -0.1178, -0.2667, -0.1111, -0.1198, -0.1515],\n",
      "        [ 0.1676, -0.0401, -0.3940, -0.2132,  0.0432, -0.0925],\n",
      "        [ 0.2258, -0.0973, -0.2644, -0.1069, -0.1576, -0.0434],\n",
      "        [ 0.2634, -0.1129, -0.3264, -0.0987, -0.0630,  0.0007],\n",
      "        [ 0.2477, -0.0720, -0.2739, -0.1411, -0.0854, -0.0680],\n",
      "        [ 0.2556, -0.1295, -0.3088, -0.1227, -0.1808,  0.0383],\n",
      "        [ 0.2727, -0.1270, -0.3115, -0.0615, -0.1040, -0.0967],\n",
      "        [ 0.3579, -0.2582, -0.1128,  0.1397, -0.1295, -0.0496],\n",
      "        [ 0.2615, -0.1641, -0.2075, -0.0838, -0.1658, -0.0320],\n",
      "        [ 0.1968, -0.1158, -0.2204, -0.1234, -0.1307, -0.0580],\n",
      "        [ 0.2416, -0.1242, -0.2722, -0.0981, -0.1288, -0.1343],\n",
      "        [ 0.3023, -0.2633, -0.2859,  0.0072, -0.2092, -0.0956],\n",
      "        [ 0.2433, -0.0310, -0.0941, -0.0427, -0.1235, -0.1132],\n",
      "        [ 0.2050, -0.1002, -0.3129, -0.1825, -0.0788, -0.0127],\n",
      "        [ 0.2740, -0.0528, -0.3114, -0.0453, -0.1001, -0.0250],\n",
      "        [ 0.1484, -0.1882, -0.2342, -0.1300, -0.2135,  0.0398],\n",
      "        [ 0.2503, -0.0796, -0.2179, -0.1279, -0.0977, -0.0811],\n",
      "        [ 0.1724, -0.0916, -0.3597, -0.2853, -0.0125, -0.0627],\n",
      "        [ 0.1745, -0.0633, -0.2598, -0.0990, -0.1101, -0.0994],\n",
      "        [ 0.2512, -0.1421, -0.2890, -0.1448, -0.1033, -0.0867],\n",
      "        [ 0.3077, -0.1065, -0.2190, -0.0431, -0.0913, -0.0902],\n",
      "        [ 0.2678, -0.2310, -0.2289, -0.0332, -0.1312,  0.0233],\n",
      "        [ 0.2481, -0.1378, -0.2671, -0.0728, -0.1192, -0.0882]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8669]) torch.Size([2, 163718]) torch.Size([163718, 7]) torch.Size([8669])\n",
      "(tensor([[-0.5461, -0.1592, -0.2237,  ..., -1.7496, -1.3085, -0.8809],\n",
      "        [-1.7643, -0.3348,  0.0271,  ..., -0.6510,  0.1749, -1.2613],\n",
      "        [ 2.0638,  0.5135,  0.6555,  ...,  1.3954, -0.3477,  0.1713],\n",
      "        ...,\n",
      "        [ 0.7204, -0.5688,  0.1585,  ...,  1.6226,  0.0027, -0.0187],\n",
      "        [ 0.1899, -1.7786,  1.1104,  ..., -0.2912, -0.1349,  1.5863],\n",
      "        [-0.8131, -1.4281,  0.3660,  ...,  1.9544, -0.1413, -0.9035]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0266, -0.0530,  0.0213,  ...,  0.1307,  0.0387, -0.0130],\n",
      "        [ 0.0761, -0.0550,  0.0304,  ...,  0.1875,  0.0037, -0.0185],\n",
      "        [ 0.2850, -0.0419, -0.1269,  ...,  0.3024,  0.0464, -0.2242],\n",
      "        ...,\n",
      "        [ 0.0808, -0.0639,  0.0231,  ...,  0.1817,  0.0010, -0.0221],\n",
      "        [ 0.0850, -0.0619,  0.0304,  ...,  0.1801, -0.0019, -0.0208],\n",
      "        [ 0.0840, -0.0586,  0.0210,  ...,  0.1899, -0.0016, -0.0229]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0010, -0.0118, -0.0121,  ...,  0.0392, -0.0431,  0.0408],\n",
      "        [-0.0441, -0.0171, -0.0107,  ...,  0.0992, -0.0616,  0.0614],\n",
      "        [ 0.2053, -0.0806, -0.0363,  ...,  0.0207, -0.1688,  0.0537],\n",
      "        ...,\n",
      "        [-0.0341, -0.0085, -0.0192,  ...,  0.0966, -0.0686,  0.0698],\n",
      "        [-0.0380, -0.0138, -0.0190,  ...,  0.0978, -0.0676,  0.0641],\n",
      "        [-0.0358, -0.0130, -0.0154,  ...,  0.0969, -0.0737,  0.0718]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2096, -0.1375, -0.2235, -0.0249, -0.1074, -0.0931],\n",
      "        [ 0.1505, -0.1182, -0.2987, -0.0950, -0.1686, -0.1096],\n",
      "        [ 0.2028, -0.2050, -0.3655, -0.2342,  0.0193, -0.0778],\n",
      "        [ 0.3256, -0.1760, -0.2628, -0.1069, -0.1461, -0.0669],\n",
      "        [ 0.2801, -0.1608, -0.2933, -0.1357, -0.1216, -0.0450],\n",
      "        [ 0.2152, -0.1428, -0.2176, -0.1423, -0.1328, -0.1520],\n",
      "        [ 0.2362, -0.0362, -0.2863, -0.1598, -0.1198, -0.1005],\n",
      "        [ 0.2747, -0.1447, -0.3132, -0.1104, -0.1458, -0.0537],\n",
      "        [ 0.2196, -0.1033, -0.2936, -0.1510, -0.1375, -0.0483],\n",
      "        [ 0.2768, -0.1733, -0.2648, -0.0579, -0.1311, -0.0617],\n",
      "        [ 0.1508, -0.0142, -0.2752, -0.2194, -0.0841, -0.0869],\n",
      "        [ 0.2602, -0.1458, -0.2268, -0.1679, -0.1632, -0.1176],\n",
      "        [ 0.1579, -0.1234, -0.2340, -0.1112, -0.1647, -0.0827],\n",
      "        [ 0.2710, -0.1712, -0.2654, -0.0713, -0.0927, -0.0926],\n",
      "        [ 0.2416, -0.0854, -0.2336, -0.0784, -0.1045, -0.0680],\n",
      "        [ 0.2354, -0.1328, -0.2639, -0.1393, -0.1148, -0.0961],\n",
      "        [ 0.1472, -0.0827, -0.2661, -0.1324, -0.1352, -0.0745],\n",
      "        [ 0.2456, -0.2051, -0.3171, -0.0814, -0.1522, -0.1023],\n",
      "        [ 0.1848, -0.0617, -0.2805, -0.1458, -0.0761, -0.1429],\n",
      "        [ 0.2111, -0.1052, -0.2466, -0.1412, -0.0691, -0.1218],\n",
      "        [ 0.2774, -0.1644, -0.3027, -0.1446, -0.1278,  0.0124],\n",
      "        [ 0.2835, -0.0983, -0.2835, -0.1376, -0.0966, -0.0397],\n",
      "        [ 0.1818, -0.1611, -0.3486, -0.2135, -0.0181,  0.0023],\n",
      "        [ 0.2113, -0.1092, -0.2553, -0.1249, -0.0400, -0.0823],\n",
      "        [ 0.2369, -0.1347, -0.2648, -0.1637, -0.1339, -0.0634],\n",
      "        [ 0.2030, -0.1089, -0.3732, -0.1721,  0.0239, -0.0847],\n",
      "        [ 0.2662, -0.2217, -0.2286, -0.0024, -0.1978, -0.0720],\n",
      "        [ 0.2132, -0.0629, -0.2643, -0.0820, -0.1073, -0.0893],\n",
      "        [ 0.2064, -0.1286, -0.2418, -0.0884, -0.1400, -0.0412],\n",
      "        [ 0.2545, -0.1414, -0.2600, -0.0344, -0.1359, -0.0622],\n",
      "        [ 0.1687, -0.0898, -0.2748, -0.1308, -0.0983, -0.0089],\n",
      "        [ 0.2916, -0.1308, -0.3104, -0.1264, -0.0902, -0.0476]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8540]) torch.Size([2, 148544]) torch.Size([148544, 7]) torch.Size([8540])\n",
      "(tensor([[ 0.4610,  0.9521, -0.4852,  ...,  0.4174,  1.1176, -0.6111],\n",
      "        [ 1.4592, -1.6701, -0.4408,  ...,  0.9976, -0.2106, -0.1398],\n",
      "        [-0.3184, -1.8224, -0.9931,  ...,  1.7820, -0.2920,  1.3441],\n",
      "        ...,\n",
      "        [-0.9364, -0.4811, -0.7616,  ...,  0.8849,  1.4415,  0.6455],\n",
      "        [ 1.6751, -1.1259,  1.3994,  ..., -0.3837,  0.2346, -1.6975],\n",
      "        [ 0.1078,  1.8636,  1.1763,  ..., -1.0677,  0.7447,  1.9439]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0784, -0.0592,  0.0121,  ...,  0.1750, -0.0126, -0.0296],\n",
      "        [ 0.3189, -0.3286,  0.1172,  ...,  0.7061,  0.1586, -0.5537],\n",
      "        [ 0.1595, -0.1374, -0.0193,  ...,  0.1580,  0.0765, -0.1288],\n",
      "        ...,\n",
      "        [ 0.0815, -0.0772,  0.0051,  ...,  0.1794, -0.0092, -0.0189],\n",
      "        [ 0.0808, -0.0742,  0.0030,  ...,  0.1838, -0.0129, -0.0159],\n",
      "        [ 0.0892, -0.0791,  0.0152,  ...,  0.1917, -0.0199, -0.0245]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0406, -0.0162, -0.0383,  ...,  0.0882, -0.0597,  0.0372],\n",
      "        [ 0.1946, -0.4569, -0.2243,  ...,  0.0240, -0.1935,  0.0486],\n",
      "        [ 0.1330, -0.0379, -0.0310,  ..., -0.0292, -0.0678,  0.0876],\n",
      "        ...,\n",
      "        [-0.0361, -0.0070, -0.0375,  ...,  0.0814, -0.0604,  0.0505],\n",
      "        [-0.0383, -0.0077, -0.0390,  ...,  0.0833, -0.0650,  0.0476],\n",
      "        [-0.0458, -0.0209, -0.0242,  ...,  0.0865, -0.0686,  0.0690]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1788, -0.1007, -0.3001, -0.1884, -0.0121, -0.0350],\n",
      "        [ 0.2266, -0.0778, -0.1935, -0.0705, -0.1358, -0.0807],\n",
      "        [ 0.2622, -0.1285, -0.2811, -0.1174, -0.0841, -0.0957],\n",
      "        [ 0.1598, -0.1172, -0.3205, -0.1573, -0.0153, -0.0289],\n",
      "        [ 0.1967, -0.0969, -0.2077, -0.1038, -0.1514, -0.1174],\n",
      "        [ 0.1830, -0.0943, -0.2743, -0.1711, -0.1576, -0.0253],\n",
      "        [ 0.1305, -0.0782, -0.2279, -0.2173, -0.1120, -0.0294],\n",
      "        [ 0.2684, -0.0461, -0.1809,  0.0695, -0.1020, -0.1543],\n",
      "        [ 0.2282, -0.1733, -0.2762, -0.1102, -0.0736, -0.0711],\n",
      "        [ 0.2954, -0.0934, -0.3223, -0.1118, -0.0627, -0.0200],\n",
      "        [ 0.2821, -0.1053, -0.3724, -0.1402, -0.0651, -0.0919],\n",
      "        [ 0.1039, -0.0751, -0.3474, -0.1906, -0.0510, -0.1112],\n",
      "        [ 0.2149, -0.1584, -0.2970, -0.2200, -0.1426, -0.1162],\n",
      "        [ 0.2503, -0.1208, -0.2059, -0.1613, -0.1656, -0.1269],\n",
      "        [ 0.2249, -0.1685, -0.2616, -0.1467, -0.1581, -0.0231],\n",
      "        [ 0.4068, -0.0916, -0.3465, -0.0701, -0.0166, -0.0316],\n",
      "        [ 0.1970, -0.1128, -0.2799, -0.1335, -0.1043, -0.0943],\n",
      "        [ 0.2419, -0.1784, -0.2827, -0.1150, -0.1339, -0.0266],\n",
      "        [ 0.3015, -0.1563, -0.2613, -0.1227, -0.1431, -0.0415],\n",
      "        [ 0.2497, -0.1387, -0.2459, -0.0848, -0.1543, -0.0919],\n",
      "        [ 0.2542, -0.1444, -0.2525, -0.0358, -0.1684, -0.0822],\n",
      "        [ 0.2397, -0.1444, -0.1985, -0.0952, -0.1627, -0.0682],\n",
      "        [ 0.2091, -0.1344, -0.2857, -0.1937, -0.1424, -0.1186],\n",
      "        [ 0.1943, -0.1696, -0.2541, -0.1966, -0.1371, -0.1295],\n",
      "        [ 0.1530, -0.1113, -0.2141, -0.1666, -0.1272, -0.0967],\n",
      "        [ 0.2345, -0.0797, -0.2967, -0.1204, -0.1436, -0.0910],\n",
      "        [ 0.2425, -0.1414, -0.2649, -0.1137, -0.1119, -0.0679],\n",
      "        [ 0.2116, -0.1229, -0.2466, -0.0428, -0.1127, -0.0326],\n",
      "        [ 0.1980, -0.0796, -0.3138, -0.1538, -0.1085, -0.0815],\n",
      "        [ 0.2777, -0.1412, -0.2713, -0.0804, -0.0868, -0.0947],\n",
      "        [ 0.1658, -0.1356, -0.2101, -0.1188, -0.1313, -0.1265],\n",
      "        [ 0.1636, -0.0959, -0.3027, -0.1770, -0.1050,  0.0218]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7859]) torch.Size([2, 141844]) torch.Size([141844, 7]) torch.Size([7859])\n",
      "(tensor([[ 0.8179,  0.5601, -2.2646,  ...,  0.3778, -2.3513, -0.0530],\n",
      "        [ 0.1751,  1.1910, -1.2761,  ...,  0.5232, -0.0433, -0.8421],\n",
      "        [ 0.9423,  0.8552, -0.6866,  ..., -1.1400, -0.4469, -0.4201],\n",
      "        ...,\n",
      "        [ 1.1542, -2.0153, -0.7403,  ...,  0.5948,  0.3877,  0.1206],\n",
      "        [ 0.7669,  1.0132,  0.7023,  ..., -0.2324,  0.3567,  1.0410],\n",
      "        [-0.4889, -0.0924,  1.0709,  ..., -0.0879, -1.0041, -1.1896]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0209, -0.0157,  0.0653,  ...,  0.0911,  0.1176,  0.0130],\n",
      "        [ 0.0184, -0.0317,  0.0447,  ...,  0.0969,  0.0821,  0.0132],\n",
      "        [ 0.0216, -0.0295,  0.0595,  ...,  0.1152,  0.0994, -0.0296],\n",
      "        ...,\n",
      "        [ 0.0894, -0.0599,  0.0442,  ...,  0.1757,  0.0045, -0.0274],\n",
      "        [ 0.0935, -0.0718,  0.0323,  ...,  0.1646,  0.0014, -0.0420],\n",
      "        [ 0.0979, -0.0751,  0.0291,  ...,  0.1676, -0.0008, -0.0417]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0539, -0.0026,  0.0564,  ...,  0.0716, -0.0393,  0.0276],\n",
      "        [-0.0550,  0.0274,  0.0277,  ...,  0.0784, -0.0425,  0.0289],\n",
      "        [ 0.0152, -0.0104,  0.0039,  ...,  0.0538, -0.0411,  0.0363],\n",
      "        ...,\n",
      "        [-0.0394, -0.0243, -0.0030,  ...,  0.0975, -0.0681,  0.0630],\n",
      "        [-0.0386, -0.0156, -0.0151,  ...,  0.0968, -0.0641,  0.0683],\n",
      "        [-0.0356, -0.0132, -0.0167,  ...,  0.0978, -0.0647,  0.0697]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2310, -0.0905, -0.3190, -0.0738, -0.1047, -0.0727],\n",
      "        [ 0.2945, -0.2122, -0.2303, -0.0579, -0.1844,  0.0106],\n",
      "        [ 0.2135, -0.1702, -0.3141, -0.0645, -0.1260, -0.0592],\n",
      "        [ 0.2507, -0.1394, -0.2310, -0.1183, -0.1607, -0.1023],\n",
      "        [ 0.2607, -0.1415, -0.3133, -0.1198, -0.1490, -0.0417],\n",
      "        [ 0.2392, -0.0959, -0.2431, -0.1456, -0.1635, -0.0969],\n",
      "        [ 0.2391, -0.0926, -0.2558, -0.0549, -0.0769, -0.1253],\n",
      "        [ 0.2999, -0.1485, -0.2686, -0.0486, -0.0429, -0.1066],\n",
      "        [ 0.1053, -0.0562, -0.3564, -0.2321,  0.0978, -0.0759],\n",
      "        [ 0.2761, -0.1685, -0.3262,  0.0463, -0.1704, -0.1848],\n",
      "        [ 0.2474, -0.1305, -0.2696, -0.0515, -0.1312, -0.0742],\n",
      "        [ 0.2012, -0.0756, -0.2653, -0.1540, -0.1229, -0.1131],\n",
      "        [ 0.1944, -0.0951, -0.1836, -0.0815, -0.1307, -0.1269],\n",
      "        [ 0.2428, -0.0867, -0.2771, -0.1708, -0.1245, -0.1207],\n",
      "        [ 0.2159, -0.0963, -0.2502, -0.1424, -0.1272, -0.0821],\n",
      "        [ 0.2098, -0.0896, -0.2324, -0.0734, -0.0807, -0.1673],\n",
      "        [ 0.1940, -0.1559, -0.2805, -0.1384, -0.1414, -0.0874],\n",
      "        [ 0.2314, -0.1317, -0.2359, -0.1110, -0.1342, -0.0858],\n",
      "        [ 0.2629, -0.0782, -0.2389, -0.0860, -0.1410, -0.0905],\n",
      "        [ 0.0821, -0.0813, -0.2787, -0.1884, -0.1430, -0.0576],\n",
      "        [ 0.2335, -0.1498, -0.2720, -0.0876, -0.0824, -0.0918],\n",
      "        [ 0.2147, -0.1507, -0.2753, -0.1328, -0.0760, -0.0637],\n",
      "        [ 0.2183, -0.1268, -0.2908, -0.1582, -0.0634, -0.0255],\n",
      "        [ 0.1646, -0.1486, -0.3319, -0.2086,  0.0311, -0.0719],\n",
      "        [ 0.2128, -0.1053, -0.2293, -0.1492, -0.0671, -0.0606],\n",
      "        [ 0.2347, -0.1123, -0.2791, -0.0882, -0.0866, -0.0984],\n",
      "        [ 0.1780, -0.0291, -0.2691, -0.0656, -0.1122, -0.1063],\n",
      "        [ 0.2800, -0.1562, -0.2292, -0.1413, -0.1287, -0.1926],\n",
      "        [ 0.2545, -0.1290, -0.2553, -0.0615, -0.1395, -0.1077],\n",
      "        [ 0.3075, -0.1615, -0.3246, -0.2131, -0.0809, -0.0048],\n",
      "        [ 0.2711, -0.1741, -0.2830, -0.0893, -0.0751, -0.0950],\n",
      "        [ 0.2711, -0.1957, -0.3025, -0.1354, -0.1698, -0.0255]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7821]) torch.Size([2, 152232]) torch.Size([152232, 7]) torch.Size([7821])\n",
      "(tensor([[-0.2888, -0.0119,  0.8069,  ..., -2.1431, -1.3632,  0.9462],\n",
      "        [-1.4667, -0.8063, -1.1179,  ..., -1.1283,  2.6642,  1.3124],\n",
      "        [ 1.7097, -1.6102,  0.9258,  ..., -2.0823,  0.1203,  0.3666],\n",
      "        ...,\n",
      "        [-0.2748, -0.0500,  2.1972,  ...,  0.7105, -1.4226, -0.8665],\n",
      "        [-0.5284,  0.1801,  0.6716,  ..., -0.5724, -0.7507, -0.2133],\n",
      "        [ 0.6543, -0.4440, -0.2321,  ...,  0.8840, -1.0714,  0.1080]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.1029, -0.0078,  0.0132,  ...,  0.1991,  0.0630, -0.0475],\n",
      "        [ 0.5233, -0.1642, -0.1755,  ...,  0.3695,  0.3044, -0.6124],\n",
      "        [ 0.2582, -0.0279, -0.0614,  ...,  0.3253,  0.0179, -0.1251],\n",
      "        ...,\n",
      "        [ 0.0848, -0.0714,  0.0127,  ...,  0.1759, -0.0065, -0.0193],\n",
      "        [ 0.0840, -0.0710,  0.0117,  ...,  0.1805, -0.0064, -0.0213],\n",
      "        [ 0.0840, -0.0710,  0.0117,  ...,  0.1805, -0.0064, -0.0213]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0352, -0.0137, -0.0498,  ...,  0.0811, -0.0622,  0.0156],\n",
      "        [ 0.4327, -0.3201, -0.0657,  ..., -0.0636, -0.2038,  0.2084],\n",
      "        [ 0.0939, -0.1247, -0.1004,  ...,  0.1272, -0.1845,  0.0109],\n",
      "        ...,\n",
      "        [-0.0338, -0.0052, -0.0127,  ...,  0.1013, -0.0693,  0.0617],\n",
      "        [-0.0348, -0.0058, -0.0113,  ...,  0.1026, -0.0718,  0.0656],\n",
      "        [-0.0348, -0.0058, -0.0113,  ...,  0.1026, -0.0718,  0.0656]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2350, -0.0711, -0.2344, -0.1250, -0.1456, -0.1029],\n",
      "        [ 0.3625, -0.1374, -0.3590, -0.1385, -0.0325, -0.0304],\n",
      "        [ 0.1665, -0.1163, -0.2119, -0.1526, -0.2344, -0.1141],\n",
      "        [ 0.1507, -0.1057, -0.3460, -0.2511,  0.0264, -0.0904],\n",
      "        [ 0.2296, -0.2028, -0.3716, -0.1500, -0.0563, -0.0572],\n",
      "        [ 0.2281, -0.0934, -0.2267, -0.1202, -0.1570, -0.1703],\n",
      "        [ 0.1226, -0.1081, -0.2549, -0.0740, -0.2512, -0.0337],\n",
      "        [ 0.2109, -0.0487, -0.3737, -0.0908, -0.0964, -0.1089],\n",
      "        [ 0.2277, -0.1028, -0.3050, -0.1739, -0.0839, -0.0358],\n",
      "        [ 0.1802, -0.1245, -0.1752, -0.1226, -0.1775, -0.0514],\n",
      "        [ 0.2264, -0.1696, -0.2611, -0.1599, -0.0996, -0.0791],\n",
      "        [ 0.2025, -0.1701, -0.3009, -0.1870, -0.1542, -0.0172],\n",
      "        [ 0.2149, -0.1052, -0.3090, -0.1549, -0.1208, -0.0662],\n",
      "        [ 0.2877, -0.1377, -0.2440, -0.1442, -0.1163, -0.1121],\n",
      "        [ 0.2592, -0.1205, -0.2644, -0.1074, -0.1070, -0.0881],\n",
      "        [ 0.2135, -0.1621, -0.2611, -0.0779, -0.1067, -0.0434],\n",
      "        [ 0.2399, -0.1516, -0.2373, -0.1362, -0.1561, -0.1138],\n",
      "        [ 0.2267, -0.1137, -0.2766, -0.1175, -0.1635, -0.0987],\n",
      "        [ 0.2773,  0.0094, -0.1610,  0.0073, -0.0939, -0.1971],\n",
      "        [ 0.2296, -0.1284, -0.1668, -0.0780, -0.1210, -0.0949],\n",
      "        [ 0.1906, -0.0544, -0.2952, -0.1072, -0.1216, -0.0564],\n",
      "        [ 0.2275, -0.1523, -0.2422, -0.1625, -0.1385, -0.0537],\n",
      "        [ 0.1789, -0.0979, -0.3379, -0.1681, -0.0971, -0.1169],\n",
      "        [ 0.1186, -0.0598, -0.2721, -0.1299, -0.0601, -0.0311],\n",
      "        [ 0.2412, -0.0775, -0.2366, -0.1094, -0.0930, -0.0597],\n",
      "        [ 0.2681, -0.2059, -0.2914, -0.0332, -0.1015, -0.0559],\n",
      "        [ 0.2021, -0.1138, -0.2958, -0.1859, -0.0265, -0.0482],\n",
      "        [ 0.1702, -0.0931, -0.2573, -0.1596, -0.1691, -0.1068],\n",
      "        [ 0.2032, -0.1456, -0.2301, -0.1321, -0.1124, -0.0556],\n",
      "        [ 0.2890, -0.3858, -0.3295, -0.1972, -0.3522, -0.1293],\n",
      "        [ 0.2214, -0.0762, -0.2688, -0.1253, -0.1028, -0.0321],\n",
      "        [ 0.2734, -0.1691, -0.3122, -0.0968, -0.1088, -0.0838]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7488]) torch.Size([2, 140604]) torch.Size([140604, 7]) torch.Size([7488])\n",
      "(tensor([[ 0.9240, -0.5057,  0.0235,  ...,  1.2455, -0.7041, -0.7133],\n",
      "        [-1.6316,  0.7035, -0.4559,  ...,  0.2762,  0.0856,  0.2133],\n",
      "        [-0.1613,  0.4841, -0.8591,  ...,  0.7491,  0.9157, -0.4596],\n",
      "        ...,\n",
      "        [ 1.1569,  0.1065,  1.3937,  ...,  0.0699,  1.3484,  0.8920],\n",
      "        [ 0.1586,  0.2194, -0.3788,  ...,  0.4646, -1.9164,  0.4182],\n",
      "        [-0.3182,  0.2641,  1.8284,  ...,  0.6338, -0.3157,  1.6483]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0374, -0.0825,  0.0662,  ...,  0.0967,  0.1323, -0.0776],\n",
      "        [ 0.0651, -0.0688,  0.0448,  ...,  0.1289,  0.0221, -0.0074],\n",
      "        [ 0.0880, -0.0801,  0.0240,  ...,  0.2088,  0.3743, -0.2558],\n",
      "        ...,\n",
      "        [ 0.0937, -0.0680,  0.0218,  ...,  0.1946, -0.0259, -0.0238],\n",
      "        [ 0.0975, -0.0713,  0.0161,  ...,  0.1978, -0.0347, -0.0234],\n",
      "        [ 0.0970, -0.0708,  0.0182,  ...,  0.1983, -0.0327, -0.0231]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.0136, -0.0122,  0.0139,  ...,  0.0146, -0.0348,  0.0487],\n",
      "        [-0.0450,  0.0086, -0.0129,  ...,  0.0810, -0.0553,  0.0641],\n",
      "        [ 0.1928, -0.1429,  0.0217,  ...,  0.0557, -0.1240,  0.1639],\n",
      "        ...,\n",
      "        [-0.0499, -0.0235, -0.0255,  ...,  0.1026, -0.0726,  0.0582],\n",
      "        [-0.0526, -0.0195, -0.0222,  ...,  0.1080, -0.0756,  0.0652],\n",
      "        [-0.0516, -0.0204, -0.0230,  ...,  0.1066, -0.0740,  0.0642]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2712, -0.1326, -0.3071, -0.1546, -0.0949, -0.0674],\n",
      "        [ 0.2082, -0.2047, -0.2660, -0.0652, -0.1680, -0.0553],\n",
      "        [ 0.1754, -0.0880, -0.2455, -0.1677, -0.1460, -0.0850],\n",
      "        [ 0.2295, -0.1439, -0.1747, -0.0913, -0.1654, -0.0771],\n",
      "        [ 0.1780, -0.1460, -0.2915, -0.1173, -0.1025, -0.0088],\n",
      "        [ 0.2666, -0.2180, -0.2464, -0.0938, -0.1701, -0.0341],\n",
      "        [ 0.2008, -0.1132, -0.3030, -0.1691, -0.1180, -0.0359],\n",
      "        [ 0.2178, -0.1306, -0.2116, -0.1022, -0.1364, -0.0591],\n",
      "        [ 0.2215, -0.1645, -0.2398, -0.1475, -0.1850, -0.0998],\n",
      "        [ 0.2446, -0.0915, -0.2524, -0.1613, -0.1121, -0.1162],\n",
      "        [ 0.2635, -0.1367, -0.2335, -0.1684, -0.1429, -0.0950],\n",
      "        [ 0.3483, -0.1510, -0.3366, -0.0919, -0.0675, -0.0359],\n",
      "        [ 0.2038, -0.1049, -0.1984, -0.1277, -0.1199, -0.0811],\n",
      "        [ 0.1851, -0.1231, -0.2897, -0.1050, -0.0365, -0.1499],\n",
      "        [ 0.2421, -0.1532, -0.2236, -0.0289, -0.1158, -0.0196],\n",
      "        [ 0.2336, -0.1316, -0.2782, -0.1127, -0.1404, -0.0234],\n",
      "        [ 0.2132, -0.1009, -0.3021, -0.1213, -0.0457, -0.0263],\n",
      "        [ 0.2336, -0.0321, -0.2807, -0.0436, -0.1171, -0.1199],\n",
      "        [ 0.2002, -0.1123, -0.2366, -0.1312, -0.1077, -0.1128],\n",
      "        [ 0.1973, -0.1325, -0.3999, -0.1522, -0.1335, -0.0093],\n",
      "        [ 0.2653, -0.1275, -0.2167, -0.0979, -0.1696, -0.0166],\n",
      "        [ 0.2241, -0.1187, -0.2305, -0.0979, -0.1037, -0.0809],\n",
      "        [ 0.1549, -0.1313, -0.2128, -0.1037, -0.1297, -0.0723],\n",
      "        [ 0.2547, -0.1101, -0.2414, -0.0447, -0.1419, -0.0476],\n",
      "        [ 0.2157, -0.1295, -0.1955, -0.1276, -0.1535, -0.0753],\n",
      "        [ 0.0809, -0.1164, -0.4416, -0.3766,  0.0785, -0.0242],\n",
      "        [ 0.2378, -0.1158, -0.2105, -0.1065, -0.1606, -0.0835],\n",
      "        [ 0.1984, -0.2040, -0.2329,  0.0174, -0.0538, -0.1346],\n",
      "        [ 0.2727, -0.1661, -0.2616, -0.1180, -0.1418, -0.0787],\n",
      "        [ 0.3518, -0.0542, -0.2449, -0.0489, -0.1030,  0.0508],\n",
      "        [ 0.2277, -0.1078, -0.1604, -0.0356, -0.0187, -0.1152],\n",
      "        [ 0.2729, -0.1715, -0.2180, -0.0517, -0.1576, -0.1055]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([6683]) torch.Size([2, 121576]) torch.Size([121576, 7]) torch.Size([6683])\n",
      "(tensor([[-0.8217, -0.1139,  0.5963,  ...,  0.3387,  0.5097, -0.9571],\n",
      "        [ 0.4789,  0.6653,  0.6633,  ...,  1.8382, -0.3552, -1.0496],\n",
      "        [-0.5610,  0.3684,  0.1477,  ..., -1.1221,  0.6193, -1.9879],\n",
      "        ...,\n",
      "        [ 1.0050,  0.3027,  0.3437,  ...,  1.1326, -0.6941,  0.0794],\n",
      "        [-0.4227, -0.6518,  2.0018,  ...,  0.2951,  1.0971, -0.5158],\n",
      "        [-0.0596, -2.0389,  0.0442,  ..., -0.5797,  1.2941,  0.1640]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0831, -0.0603,  0.0430,  ...,  0.1377,  0.0277, -0.0194],\n",
      "        [ 0.0513, -0.0537,  0.0545,  ...,  0.1019,  0.0419, -0.0049],\n",
      "        [ 0.1234, -0.0716,  0.0299,  ...,  0.2057, -0.0110, -0.0422],\n",
      "        ...,\n",
      "        [ 0.1204, -0.0730,  0.0235,  ...,  0.1983, -0.0073, -0.0432],\n",
      "        [ 0.1176, -0.0701,  0.0200,  ...,  0.2048, -0.0181, -0.0285],\n",
      "        [ 0.0988, -0.0551,  0.0531,  ...,  0.1609,  0.0256, -0.0477]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0570,  0.0099, -0.0165,  ...,  0.0992, -0.0565,  0.0549],\n",
      "        [-0.0482,  0.0104, -0.0009,  ...,  0.0821, -0.0395,  0.0472],\n",
      "        [-0.0647, -0.0258, -0.0167,  ...,  0.1229, -0.0759,  0.0812],\n",
      "        ...,\n",
      "        [-0.0628, -0.0223, -0.0154,  ...,  0.1184, -0.0704,  0.0779],\n",
      "        [-0.0615, -0.0265, -0.0122,  ...,  0.1239, -0.0761,  0.0658],\n",
      "        [-0.0721, -0.0096, -0.0069,  ...,  0.0941, -0.0675,  0.0766]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1932, -0.0805, -0.2160, -0.1533, -0.1477, -0.0715],\n",
      "        [ 0.2321, -0.1081, -0.3382, -0.1156, -0.0981, -0.0992],\n",
      "        [ 0.2911, -0.1582, -0.1632, -0.0196, -0.1314, -0.1005],\n",
      "        [ 0.2360, -0.0874, -0.2753, -0.1463, -0.1812, -0.0624],\n",
      "        [ 0.1667, -0.1264, -0.2853, -0.1414, -0.1345, -0.0159],\n",
      "        [ 0.1875, -0.1394, -0.3046, -0.1863, -0.0711, -0.0210],\n",
      "        [ 0.2406, -0.2048, -0.1485, -0.0994, -0.0950, -0.1442],\n",
      "        [ 0.3118, -0.2121, -0.3514, -0.1197, -0.2085, -0.0239],\n",
      "        [ 0.2337, -0.1362, -0.3221, -0.0997, -0.0912, -0.0414],\n",
      "        [ 0.2147, -0.1165, -0.2874, -0.1482, -0.0483, -0.0325],\n",
      "        [ 0.2988, -0.1276, -0.2975, -0.0605, -0.1217, -0.0388],\n",
      "        [ 0.1864, -0.1727, -0.2134, -0.1142, -0.1298, -0.1301],\n",
      "        [ 0.2209, -0.1139, -0.2685, -0.0895, -0.1196, -0.0214],\n",
      "        [ 0.2715, -0.1701, -0.2572, -0.0966, -0.1354,  0.0113],\n",
      "        [ 0.2311, -0.0761, -0.2922, -0.1344, -0.0877, -0.0715],\n",
      "        [ 0.2284, -0.1500, -0.2981, -0.2133, -0.1254, -0.0621],\n",
      "        [ 0.2407, -0.1415, -0.2767, -0.0536, -0.0666, -0.1069],\n",
      "        [ 0.2013, -0.1092, -0.2338, -0.1148, -0.0584, -0.0843],\n",
      "        [ 0.2491, -0.1666, -0.2841, -0.0374, -0.1319, -0.1153],\n",
      "        [ 0.2562, -0.1817, -0.3677, -0.1726, -0.0736, -0.0049],\n",
      "        [ 0.3394, -0.1967, -0.3220, -0.0299, -0.0228, -0.1453],\n",
      "        [ 0.2197, -0.1260, -0.2066, -0.1030, -0.1294, -0.0858],\n",
      "        [ 0.1319, -0.0340, -0.2621, -0.0601, -0.1250, -0.0068],\n",
      "        [ 0.1804, -0.1678, -0.2709, -0.1438, -0.1237, -0.0700],\n",
      "        [ 0.2577, -0.1431, -0.3070, -0.1370, -0.1627, -0.0310],\n",
      "        [ 0.0850, -0.0039, -0.4161, -0.4278,  0.1552, -0.0803],\n",
      "        [ 0.2264, -0.1517, -0.3828, -0.1810, -0.0365, -0.0692],\n",
      "        [ 0.2035, -0.1276, -0.3502, -0.2101, -0.0990, -0.0647],\n",
      "        [ 0.2208, -0.1988, -0.3089, -0.1293, -0.1050, -0.0704],\n",
      "        [ 0.1675, -0.1180, -0.2868, -0.1481, -0.1147, -0.0161],\n",
      "        [ 0.1955, -0.1118, -0.2699, -0.0529, -0.1127, -0.0461],\n",
      "        [ 0.1579, -0.1254, -0.3576, -0.2195, -0.0201, -0.1076]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8327]) torch.Size([2, 130064]) torch.Size([130064, 7]) torch.Size([8327])\n",
      "(tensor([[-0.9159, -0.1774, -0.0124,  ...,  2.7151, -0.1316, -1.2577],\n",
      "        [ 3.1932, -0.0189,  1.5076,  ...,  0.0996, -0.6238, -1.1966],\n",
      "        [ 0.0986, -0.3694,  0.2062,  ...,  1.0724, -0.1467, -1.0764],\n",
      "        ...,\n",
      "        [ 0.4921, -0.7751, -0.2266,  ..., -0.4994,  1.5204,  0.1559],\n",
      "        [ 0.4717, -0.7072, -0.5868,  ...,  0.3025,  0.1723, -0.0218],\n",
      "        [ 0.5352,  0.0098, -0.5056,  ...,  0.1091,  0.4903,  0.5863]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.2600,  0.2368,  0.3304,  ...,  1.9409,  0.5704, -1.5020],\n",
      "        [ 0.3421,  0.0661,  0.4414,  ...,  2.1278,  0.8122, -1.6248],\n",
      "        [ 0.3032,  0.0868,  0.4312,  ...,  1.8782,  0.6086, -1.5334],\n",
      "        ...,\n",
      "        [ 0.0998, -0.0561,  0.0042,  ...,  0.2178, -0.0402, -0.0361],\n",
      "        [ 0.1012, -0.0465,  0.0030,  ...,  0.2268, -0.0461, -0.0365],\n",
      "        [ 0.0996, -0.0555,  0.0047,  ...,  0.2183, -0.0392, -0.0355]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2402, -1.2991, -0.7154,  ..., -0.1320, -0.8903,  0.5052],\n",
      "        [ 0.4794, -1.3332, -0.7358,  ..., -0.0566, -0.9557,  0.4871],\n",
      "        [ 0.3073, -1.3006, -0.6811,  ..., -0.0751, -0.8176,  0.4282],\n",
      "        ...,\n",
      "        [-0.0618, -0.0240, -0.0283,  ...,  0.1077, -0.0857,  0.0648],\n",
      "        [-0.0595, -0.0311, -0.0317,  ...,  0.1148, -0.0887,  0.0592],\n",
      "        [-0.0619, -0.0236, -0.0286,  ...,  0.1082, -0.0856,  0.0653]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1337, -0.1580, -0.3479, -0.2879, -0.0937,  0.0350],\n",
      "        [ 0.2693, -0.1365, -0.2629, -0.0734, -0.1357, -0.0779],\n",
      "        [ 0.2606, -0.1362, -0.3047, -0.1381, -0.1072, -0.0707],\n",
      "        [ 0.2669, -0.0942, -0.2568, -0.0968, -0.1283, -0.0848],\n",
      "        [ 0.1723, -0.1214, -0.3257, -0.0799, -0.0827, -0.1063],\n",
      "        [ 0.2240, -0.1396, -0.2848, -0.1197, -0.1267, -0.0701],\n",
      "        [ 0.1410, -0.1201, -0.2149, -0.1602, -0.2170, -0.2138],\n",
      "        [ 0.2064, -0.1055, -0.2636, -0.1239, -0.0755, -0.0795],\n",
      "        [ 0.2463, -0.2183, -0.3439, -0.1135, -0.1216, -0.0819],\n",
      "        [ 0.1428, -0.1557, -0.3292, -0.2352, -0.0206, -0.0740],\n",
      "        [ 0.1588, -0.0788, -0.3029, -0.1882, -0.1218, -0.0805],\n",
      "        [ 0.2323, -0.1666, -0.2529, -0.1339, -0.1422, -0.1124],\n",
      "        [ 0.1878, -0.1347, -0.2213, -0.1082, -0.1371, -0.0856],\n",
      "        [ 0.1921, -0.1054, -0.2270, -0.1150, -0.1431, -0.0831],\n",
      "        [ 0.2258, -0.1551, -0.2932, -0.1262, -0.0547, -0.0954],\n",
      "        [ 0.1560, -0.0628, -0.2362, -0.0637, -0.0712, -0.1036],\n",
      "        [ 0.2095, -0.1435, -0.2495, -0.1174, -0.1889, -0.0746],\n",
      "        [ 0.2558, -0.0988, -0.2104, -0.0979, -0.1250, -0.0699],\n",
      "        [ 0.2153, -0.1226, -0.2377, -0.0839, -0.0887, -0.1308],\n",
      "        [ 0.2695, -0.1425, -0.2372, -0.1240, -0.0970, -0.0912],\n",
      "        [ 0.2110, -0.1823, -0.3066, -0.1401, -0.1313, -0.0464],\n",
      "        [ 0.2883, -0.1791, -0.2926, -0.1529, -0.0818, -0.0292],\n",
      "        [ 0.2030, -0.0812, -0.3229, -0.2194, -0.1236, -0.0662],\n",
      "        [ 0.1933, -0.1060, -0.2333, -0.0895, -0.0607, -0.0968],\n",
      "        [ 0.1897, -0.1133, -0.2479, -0.1397, -0.1019, -0.0890],\n",
      "        [ 0.1970, -0.1118, -0.3298, -0.1746, -0.1174, -0.0546],\n",
      "        [ 0.1889, -0.0875, -0.2699, -0.1125, -0.0983, -0.1031],\n",
      "        [ 0.2962, -0.1022, -0.3501, -0.1696, -0.1024, -0.0066],\n",
      "        [ 0.2102, -0.1378, -0.2428, -0.1559, -0.1310, -0.0303],\n",
      "        [ 0.2689, -0.1347, -0.2858, -0.1067, -0.1157, -0.0393],\n",
      "        [ 0.1873, -0.1721, -0.2555, -0.0779, -0.1882, -0.0290],\n",
      "        [ 0.3180, -0.1959, -0.2819, -0.0757, -0.1399, -0.0741]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7353]) torch.Size([2, 129892]) torch.Size([129892, 7]) torch.Size([7353])\n",
      "(tensor([[-1.3649,  0.6933,  0.2553,  ..., -2.0778, -0.2785, -0.4413],\n",
      "        [ 1.1212, -0.4535, -0.4265,  ...,  0.3381,  1.2412,  0.2528],\n",
      "        [-1.0605, -0.2514, -0.1895,  ..., -0.7811, -0.0933, -0.6186],\n",
      "        ...,\n",
      "        [-0.6758,  0.4327, -0.9752,  ..., -1.4320,  1.7591,  0.9184],\n",
      "        [-0.2251, -0.7839,  1.0275,  ...,  0.5537,  0.7082,  0.0337],\n",
      "        [ 0.7202, -0.2111,  0.0651,  ...,  0.8676,  0.0897, -0.0834]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0596, -0.0279,  0.0217,  ...,  0.1540,  0.0670, -0.0585],\n",
      "        [ 0.0717, -0.0603, -0.0054,  ...,  0.1684,  0.1002, -0.0959],\n",
      "        [ 0.0855, -0.0540,  0.0061,  ...,  0.1640,  0.0138, -0.0464],\n",
      "        ...,\n",
      "        [ 0.0927, -0.0770, -0.0030,  ...,  0.1876, -0.0394, -0.0347],\n",
      "        [ 0.1083, -0.0520, -0.0024,  ...,  0.2323, -0.0466, -0.0335],\n",
      "        [ 0.0875, -0.0535,  0.0020,  ...,  0.2086, -0.0322, -0.0357]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0281,  0.0149, -0.0136,  ...,  0.0610, -0.0342,  0.0186],\n",
      "        [ 0.0608,  0.0059,  0.0006,  ...,  0.0437, -0.0377,  0.0639],\n",
      "        [-0.0531,  0.0037, -0.0226,  ...,  0.0938, -0.0522,  0.0566],\n",
      "        ...,\n",
      "        [-0.0449, -0.0300, -0.0156,  ...,  0.0936, -0.0703,  0.0603],\n",
      "        [-0.0566, -0.0300, -0.0232,  ...,  0.1117, -0.0955,  0.0635],\n",
      "        [-0.0460, -0.0306, -0.0182,  ...,  0.0958, -0.0851,  0.0646]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2537, -0.1097, -0.1759,  0.0466, -0.1171, -0.0573],\n",
      "        [ 0.1916, -0.0884, -0.3310, -0.0892, -0.1073, -0.1815],\n",
      "        [ 0.1786, -0.0787, -0.2004, -0.0591, -0.1107, -0.0651],\n",
      "        [ 0.2198, -0.1905, -0.2654, -0.1821, -0.1645, -0.0067],\n",
      "        [ 0.2573, -0.1164, -0.3481, -0.1680, -0.0565, -0.1538],\n",
      "        [ 0.2330, -0.2210, -0.2580, -0.0770, -0.1344, -0.0962],\n",
      "        [ 0.4012, -0.1306, -0.2855, -0.0463, -0.0996, -0.0045],\n",
      "        [ 0.2383, -0.1030, -0.2182, -0.1718, -0.1720, -0.0714],\n",
      "        [ 0.2569, -0.1501, -0.1875, -0.0630, -0.1662, -0.0600],\n",
      "        [ 0.2777, -0.2037, -0.1966, -0.1349, -0.1758, -0.1096],\n",
      "        [ 0.0983, -0.0622, -0.2699, -0.2254, -0.1162, -0.0669],\n",
      "        [ 0.2639, -0.1377, -0.2476, -0.0986, -0.1290, -0.0787],\n",
      "        [ 0.2986, -0.1436, -0.3191, -0.1292, -0.0742, -0.0958],\n",
      "        [ 0.2589, -0.0890, -0.2847, -0.1461, -0.1048, -0.0916],\n",
      "        [ 0.1782, -0.1028, -0.3411, -0.2034, -0.0859, -0.0143],\n",
      "        [ 0.2155, -0.1246, -0.2762, -0.1340, -0.1228, -0.0414],\n",
      "        [ 0.2927, -0.1046, -0.2853, -0.0226, -0.0227, -0.1070],\n",
      "        [ 0.1673, -0.0782, -0.2889, -0.1377, -0.1020,  0.0008],\n",
      "        [ 0.2238, -0.1230, -0.2988, -0.1833, -0.1322, -0.0175],\n",
      "        [ 0.2453, -0.1366, -0.3373, -0.1079, -0.1498, -0.0938],\n",
      "        [ 0.2180, -0.0945, -0.2342, -0.1336, -0.1774, -0.0127],\n",
      "        [ 0.1375, -0.0951, -0.3481, -0.2315, -0.1017, -0.0723],\n",
      "        [ 0.2376, -0.0832, -0.2676, -0.1184, -0.1039, -0.0451],\n",
      "        [ 0.1813, -0.1545, -0.3729, -0.2879, -0.0319, -0.0448],\n",
      "        [ 0.2660, -0.1147, -0.2392, -0.0327, -0.0600, -0.0869],\n",
      "        [ 0.2368, -0.1115, -0.3144, -0.1186, -0.0819, -0.0122],\n",
      "        [ 0.1382, -0.0683, -0.2932, -0.1329, -0.0659, -0.0780],\n",
      "        [ 0.1752, -0.1880, -0.2639, -0.0848, -0.1038, -0.0815],\n",
      "        [ 0.2383, -0.1234, -0.2557, -0.0605, -0.1162, -0.0976],\n",
      "        [ 0.1944, -0.1339, -0.1915, -0.1010, -0.1162, -0.0790],\n",
      "        [ 0.2236, -0.0986, -0.2520, -0.1473, -0.1606, -0.0366],\n",
      "        [ 0.1184, -0.0764, -0.2646, -0.2404, -0.1203, -0.1010]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7499]) torch.Size([2, 135990]) torch.Size([135990, 7]) torch.Size([7499])\n",
      "(tensor([[-0.8805,  0.0959, -0.9344,  ..., -0.4993,  0.2344,  0.4580],\n",
      "        [ 1.5696,  0.5099,  0.5508,  ...,  0.7371,  0.9407, -1.1047],\n",
      "        [ 2.6183,  1.4030,  1.4897,  ...,  1.2909, -0.5717, -0.9480],\n",
      "        ...,\n",
      "        [-1.4831, -0.7150, -1.0663,  ...,  0.3620, -1.0465,  0.2354],\n",
      "        [-0.3020,  0.3617,  0.3019,  ...,  1.8375,  0.8132,  0.1397],\n",
      "        [-0.4537,  0.2558, -0.5219,  ..., -0.0218, -1.9686,  1.4398]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.1048,  0.0458,  0.0120,  ...,  0.2174,  0.3964, -0.1196],\n",
      "        [ 0.0152, -0.0049,  0.0573,  ...,  0.1059,  0.1981, -0.0635],\n",
      "        [ 0.0783, -0.0513,  0.0298,  ...,  0.1815,  0.0061, -0.0121],\n",
      "        ...,\n",
      "        [ 0.0798, -0.0589,  0.0219,  ...,  0.1830, -0.0091, -0.0165],\n",
      "        [ 0.0895, -0.0599,  0.0200,  ...,  0.1931, -0.0196, -0.0199],\n",
      "        [ 0.0795, -0.0611,  0.0207,  ...,  0.1828,  0.0023, -0.0152]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1064, -0.2424,  0.0681,  ...,  0.1292, -0.2068,  0.1630],\n",
      "        [-0.0188, -0.0801,  0.0601,  ...,  0.0808, -0.0814,  0.0664],\n",
      "        [-0.0399, -0.0134, -0.0023,  ...,  0.0917, -0.0761,  0.0831],\n",
      "        ...,\n",
      "        [-0.0455, -0.0120, -0.0069,  ...,  0.0994, -0.0697,  0.0911],\n",
      "        [-0.0539, -0.0190, -0.0128,  ...,  0.1081, -0.0751,  0.0936],\n",
      "        [-0.0264, -0.0085, -0.0096,  ...,  0.0881, -0.0740,  0.0789]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2587, -0.1252, -0.3166, -0.1228, -0.1497, -0.0295],\n",
      "        [ 0.2197, -0.1293, -0.2305, -0.2445, -0.0545, -0.0310],\n",
      "        [ 0.1912, -0.1608, -0.3694, -0.1420,  0.0519, -0.1459],\n",
      "        [ 0.2635, -0.2107, -0.3217, -0.1944, -0.1045, -0.0347],\n",
      "        [ 0.2107, -0.1312, -0.2182, -0.1223, -0.2093, -0.1130],\n",
      "        [ 0.2999, -0.0725, -0.2692, -0.0296,  0.0175, -0.0437],\n",
      "        [ 0.1694, -0.1162, -0.2880, -0.2847, -0.1308, -0.0290],\n",
      "        [ 0.2766, -0.1049, -0.2467, -0.1158, -0.1465, -0.0713],\n",
      "        [ 0.3495, -0.2087, -0.2364, -0.0029, -0.1496,  0.0086],\n",
      "        [ 0.1119, -0.0908, -0.2728, -0.2105, -0.0491, -0.0238],\n",
      "        [ 0.2298, -0.1023, -0.2379, -0.0777, -0.0990, -0.0688],\n",
      "        [ 0.2733, -0.1898, -0.2784, -0.0589, -0.1774, -0.0747],\n",
      "        [ 0.2090, -0.1347, -0.2161, -0.1435, -0.1421, -0.0185],\n",
      "        [ 0.2579, -0.1289, -0.2766, -0.1197, -0.1067, -0.0976],\n",
      "        [ 0.2135, -0.1505, -0.2367, -0.0620, -0.0995, -0.0418],\n",
      "        [ 0.2047, -0.1083, -0.1596, -0.0327, -0.1386, -0.1049],\n",
      "        [ 0.1866, -0.1852, -0.2970, -0.1461, -0.1337, -0.0483],\n",
      "        [ 0.2489, -0.1044, -0.1934, -0.1434, -0.0980, -0.1241],\n",
      "        [ 0.1487, -0.0909, -0.2251, -0.0810, -0.1074, -0.0978],\n",
      "        [ 0.1797, -0.0877, -0.2337, -0.2146, -0.1179, -0.0299],\n",
      "        [ 0.2470, -0.1251, -0.2578, -0.2013, -0.1472, -0.0327],\n",
      "        [ 0.2543, -0.0706, -0.2902, -0.1150, -0.1034, -0.0948],\n",
      "        [ 0.1879, -0.1557, -0.3392, -0.1657, -0.1081, -0.0315],\n",
      "        [ 0.2638, -0.1605, -0.2786, -0.0830, -0.1303, -0.0438],\n",
      "        [ 0.1853, -0.1173, -0.2568, -0.1650, -0.1377, -0.0332],\n",
      "        [ 0.2175, -0.1202, -0.2146, -0.1117, -0.1409, -0.0058],\n",
      "        [ 0.1946, -0.0380, -0.4021, -0.2485,  0.0764,  0.0176],\n",
      "        [ 0.2629, -0.2096, -0.3777, -0.0904, -0.1044, -0.0195],\n",
      "        [ 0.2710, -0.1697, -0.3532, -0.1600, -0.0788, -0.0312],\n",
      "        [ 0.2252, -0.0796, -0.3286, -0.1423, -0.0538, -0.1298],\n",
      "        [ 0.1672, -0.1197, -0.1796, -0.1812, -0.2101, -0.1476],\n",
      "        [ 0.2315, -0.1436, -0.3068, -0.1975, -0.0984, -0.0175]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7341]) torch.Size([2, 123702]) torch.Size([123702, 7]) torch.Size([7341])\n",
      "(tensor([[-0.1019,  0.4130,  0.4663,  ..., -0.8417,  0.3076,  2.8032],\n",
      "        [ 0.7934,  0.0332,  0.3509,  ..., -0.0075,  1.2742,  0.4259],\n",
      "        [ 1.3914, -1.3011,  0.4243,  ...,  1.1670,  0.1395, -1.8142],\n",
      "        ...,\n",
      "        [-0.0371,  0.1030,  0.5083,  ...,  0.7524,  1.4667,  1.1386],\n",
      "        [ 0.0504, -1.2298, -0.1540,  ...,  0.3010,  0.0248,  0.5149],\n",
      "        [-0.6627, -1.1375, -0.4795,  ...,  0.7823,  1.0354,  0.4683]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 7.2408e-02, -9.2801e-02,  1.9769e-02,  ...,  1.0574e-01,\n",
      "          2.4023e-03, -3.0736e-02],\n",
      "        [ 6.2038e-02, -6.1958e-02,  6.5832e-02,  ...,  1.4213e-01,\n",
      "          3.3515e-02, -2.3342e-02],\n",
      "        [ 1.5620e+00, -1.4958e+00,  8.6993e-01,  ...,  2.6713e+00,\n",
      "          8.2153e-01, -2.1379e+00],\n",
      "        ...,\n",
      "        [ 9.0001e-02, -5.0064e-02,  2.7570e-02,  ...,  1.8493e-01,\n",
      "         -1.4500e-02, -2.7391e-02],\n",
      "        [ 9.4830e-02, -6.4471e-02,  2.1314e-02,  ...,  1.9533e-01,\n",
      "         -2.2516e-02, -3.6021e-02],\n",
      "        [ 9.6571e-02, -6.5335e-02,  1.7583e-02,  ...,  1.9375e-01,\n",
      "         -2.5273e-02, -3.5083e-02]], grad_fn=<AddmmBackward0>), tensor([[-8.0937e-02,  1.0146e-03,  3.9087e-02,  ...,  8.6085e-02,\n",
      "         -8.9361e-02,  4.1571e-02],\n",
      "        [-7.4575e-02, -2.2388e-02,  3.6944e-02,  ...,  7.2812e-02,\n",
      "         -9.6199e-02,  3.3214e-02],\n",
      "        [ 8.8540e-01, -2.2842e+00, -1.0161e+00,  ...,  5.7795e-01,\n",
      "         -7.1282e-01,  3.5946e-01],\n",
      "        ...,\n",
      "        [-4.2186e-02, -2.4236e-02, -1.3831e-02,  ...,  1.0063e-01,\n",
      "         -8.6670e-02,  7.7361e-02],\n",
      "        [-4.5767e-02, -2.8454e-02, -1.7087e-02,  ...,  9.6274e-02,\n",
      "         -9.0909e-02,  7.3498e-02],\n",
      "        [-4.5110e-02, -2.6086e-02, -1.9072e-02,  ...,  9.6778e-02,\n",
      "         -8.9652e-02,  7.4239e-02]], grad_fn=<AddmmBackward0>), tensor([[ 0.0249, -0.1003, -0.3471, -0.2880, -0.0539, -0.0850],\n",
      "        [ 0.1608,  0.0094, -0.2285, -0.0673, -0.1085, -0.0923],\n",
      "        [ 0.1815, -0.1003, -0.2658, -0.1284, -0.1349,  0.0307],\n",
      "        [ 0.2643, -0.1249, -0.3122, -0.1390, -0.1348, -0.0654],\n",
      "        [ 0.2020, -0.1445, -0.3221, -0.1183, -0.1823, -0.0333],\n",
      "        [ 0.2513, -0.0472, -0.3040, -0.1479, -0.0954, -0.0454],\n",
      "        [ 0.1842, -0.1348, -0.2633, -0.1064, -0.1433, -0.1123],\n",
      "        [ 0.2040, -0.1647, -0.2028, -0.0819, -0.1438, -0.1103],\n",
      "        [ 0.2394, -0.1546, -0.2941, -0.1982, -0.1081, -0.0613],\n",
      "        [ 0.1498, -0.0922, -0.2258, -0.1208, -0.0737, -0.0819],\n",
      "        [ 0.2094, -0.1674, -0.3182, -0.2220, -0.2009, -0.1034],\n",
      "        [ 0.2581, -0.0629, -0.2824, -0.1409, -0.1488, -0.1223],\n",
      "        [ 0.1976, -0.1208, -0.2278, -0.0993, -0.1783, -0.0551],\n",
      "        [ 0.2181, -0.1145, -0.2999, -0.1686, -0.1143, -0.0947],\n",
      "        [ 0.2374, -0.1330, -0.2722, -0.1122, -0.1524, -0.0906],\n",
      "        [ 0.2710, -0.2120, -0.2241, -0.1317, -0.1702, -0.0672],\n",
      "        [ 0.2388, -0.1217, -0.2866, -0.1569, -0.1010, -0.1065],\n",
      "        [ 0.2745, -0.1406, -0.2453, -0.1354, -0.1264, -0.0810],\n",
      "        [ 0.1955, -0.0520, -0.2591, -0.1041, -0.0915, -0.0521],\n",
      "        [ 0.3327, -0.0757, -0.3498, -0.1979, -0.0071, -0.1049],\n",
      "        [ 0.2817, -0.1020, -0.3050, -0.1386, -0.1673, -0.0233],\n",
      "        [ 0.2155, -0.1388, -0.2775, -0.2466, -0.1655, -0.0610],\n",
      "        [-0.0553, -0.0046, -0.4563, -0.4759, -0.0670, -0.0762],\n",
      "        [ 0.2300, -0.1178, -0.2883, -0.1179, -0.0690, -0.0548],\n",
      "        [ 0.2531, -0.1123, -0.2772, -0.1199, -0.1551,  0.0274],\n",
      "        [ 0.2855, -0.1476, -0.2208, -0.0868, -0.1180, -0.0617],\n",
      "        [ 0.1994, -0.1176, -0.2613, -0.1181, -0.1143,  0.0229],\n",
      "        [ 0.1818, -0.1380, -0.2793, -0.0689, -0.1543, -0.0697],\n",
      "        [ 0.1795, -0.0946, -0.2719, -0.0225, -0.0225, -0.0562],\n",
      "        [ 0.1802, -0.1235, -0.2807, -0.1959, -0.0965, -0.0385],\n",
      "        [ 0.3751, -0.2484, -0.2270, -0.0368, -0.0951,  0.0235],\n",
      "        [ 0.2834, -0.1223, -0.3167, -0.1089, -0.0116, -0.0648]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([6917]) torch.Size([2, 115692]) torch.Size([115692, 7]) torch.Size([6917])\n",
      "(tensor([[ 0.4122,  0.1904,  1.1789,  ..., -0.5633, -0.8411, -2.0165],\n",
      "        [ 1.8477, -1.0752,  0.6922,  ...,  1.8885,  0.0883, -0.1882],\n",
      "        [-0.9446,  0.3802, -1.3858,  ...,  1.4423, -0.4775, -1.6528],\n",
      "        ...,\n",
      "        [ 0.3395, -0.9521, -1.5412,  ...,  0.2784,  1.4131,  0.2333],\n",
      "        [ 0.4520,  0.3930,  0.2820,  ..., -1.2007,  1.4170, -0.2140],\n",
      "        [ 1.0714, -1.7158, -0.3130,  ...,  0.1828,  0.6329,  1.5938]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0561, -0.0425,  0.0087,  ...,  0.1489,  0.0596,  0.0187],\n",
      "        [ 0.3064, -0.0792,  0.0690,  ...,  0.4673,  0.1220, -0.1154],\n",
      "        [ 0.7817, -0.3166, -0.1801,  ...,  0.6550,  0.4684, -0.9799],\n",
      "        ...,\n",
      "        [ 0.0818, -0.0601, -0.0095,  ...,  0.1944, -0.0244, -0.0288],\n",
      "        [ 0.0929, -0.0674, -0.0244,  ...,  0.2045, -0.0297, -0.0245],\n",
      "        [ 0.0898, -0.0677, -0.0172,  ...,  0.1964, -0.0233, -0.0266]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0057, -0.0292, -0.0623,  ...,  0.0929, -0.0758, -0.0063],\n",
      "        [ 0.3885, -0.2492, -0.2189,  ...,  0.1020, -0.0517, -0.0473],\n",
      "        [ 0.6367, -0.7793, -0.1949,  ..., -0.0713, -0.1607,  0.3076],\n",
      "        ...,\n",
      "        [-0.0476, -0.0159, -0.0177,  ...,  0.1142, -0.0741,  0.0460],\n",
      "        [-0.0421, -0.0095, -0.0161,  ...,  0.1121, -0.0783,  0.0578],\n",
      "        [-0.0457, -0.0100, -0.0176,  ...,  0.1087, -0.0715,  0.0569]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 2.1487e-01, -1.1122e-01, -2.0157e-01, -1.4558e-01, -1.5677e-01,\n",
      "         -7.4054e-02],\n",
      "        [ 1.4263e-01, -1.4325e-01, -3.3910e-01, -4.3664e-02, -1.5642e-02,\n",
      "          2.2494e-02],\n",
      "        [ 2.1549e-01, -9.0401e-02, -2.6682e-01, -1.3205e-01, -1.1586e-01,\n",
      "         -6.8484e-02],\n",
      "        [ 1.9197e-01, -1.4594e-01, -1.5030e-01,  5.8087e-02, -2.1047e-01,\n",
      "         -7.0382e-02],\n",
      "        [ 2.3799e-01, -1.8445e-01, -3.4421e-01, -9.7996e-02, -8.6670e-02,\n",
      "         -8.5624e-02],\n",
      "        [ 1.8432e-01, -1.2965e-01, -2.5459e-01, -1.1292e-01, -9.9404e-02,\n",
      "         -4.8982e-02],\n",
      "        [ 1.9241e-01, -4.3362e-02, -2.3524e-01, -1.0369e-01, -9.9171e-02,\n",
      "         -1.2040e-01],\n",
      "        [ 2.4320e-01, -9.1860e-02, -2.2928e-01, -5.9606e-02, -5.0052e-02,\n",
      "         -1.4436e-01],\n",
      "        [ 2.0544e-01, -1.4852e-01, -2.5921e-01, -1.4305e-01, -1.2865e-01,\n",
      "         -9.4619e-02],\n",
      "        [ 2.1517e-01, -1.2708e-01, -2.3452e-01, -1.1858e-01, -1.3026e-01,\n",
      "         -3.2130e-02],\n",
      "        [ 1.2271e-01,  3.6622e-02, -1.1232e-01, -2.2379e-01, -1.8688e-01,\n",
      "         -1.1715e-02],\n",
      "        [ 2.9666e-01, -1.2733e-01, -2.4666e-01, -1.3861e-01, -1.1639e-01,\n",
      "         -4.2426e-02],\n",
      "        [ 2.7107e-01, -1.5948e-01, -3.1542e-01, -3.8921e-02, -7.8821e-02,\n",
      "         -1.6977e-03],\n",
      "        [ 2.3084e-01, -4.1624e-02, -3.8240e-01, -1.7519e-01, -8.7938e-02,\n",
      "         -2.1299e-02],\n",
      "        [ 1.5271e-01, -7.4699e-02, -4.7776e-01, -1.9543e-01,  5.6057e-02,\n",
      "          3.0466e-02],\n",
      "        [ 1.5083e-01, -1.5080e-01, -1.7967e-01, -7.5358e-02, -1.0573e-01,\n",
      "         -7.3104e-02],\n",
      "        [ 2.7788e-01, -4.8652e-02, -3.1902e-01, -7.3134e-02, -2.9855e-02,\n",
      "         -1.8773e-01],\n",
      "        [ 2.6300e-01, -2.2418e-01, -3.6075e-01, -1.7192e-01, -9.9479e-02,\n",
      "         -5.8949e-02],\n",
      "        [ 1.4625e-01, -1.1341e-01, -2.6999e-01, -1.3851e-01, -1.0262e-01,\n",
      "         -5.7304e-02],\n",
      "        [ 2.4831e-01, -2.0219e-01, -2.9655e-01, -1.7106e-01, -1.0159e-01,\n",
      "         -3.5114e-02],\n",
      "        [ 2.2101e-01, -1.0968e-01, -2.2894e-01, -9.4305e-02, -6.4531e-02,\n",
      "         -8.7810e-02],\n",
      "        [ 2.4436e-01, -1.5514e-01, -3.1317e-01, -1.2168e-01, -1.3529e-01,\n",
      "         -3.3314e-02],\n",
      "        [ 2.4032e-01, -1.4764e-01, -3.2883e-01, -1.2217e-01, -8.6567e-02,\n",
      "         -1.0934e-04],\n",
      "        [ 2.0103e-01, -8.4152e-02, -2.4204e-01, -9.9243e-02, -1.5460e-01,\n",
      "         -7.5254e-02],\n",
      "        [ 1.8545e-01, -9.5464e-02, -3.7096e-01, -1.5528e-01,  5.3104e-02,\n",
      "         -1.3345e-01],\n",
      "        [ 2.1004e-01, -1.4292e-01, -3.2531e-01, -1.7822e-01, -2.0104e-02,\n",
      "         -5.2776e-02],\n",
      "        [ 2.2767e-01, -1.1088e-01, -2.6943e-01, -1.2010e-01, -1.1846e-01,\n",
      "         -7.0944e-02],\n",
      "        [ 2.1604e-01, -9.1066e-02, -2.3948e-01, -9.7662e-02, -7.2691e-02,\n",
      "         -6.5966e-02],\n",
      "        [ 1.9719e-01, -6.5427e-02, -2.7807e-01, -1.4753e-01, -5.0006e-02,\n",
      "         -1.4293e-01],\n",
      "        [ 2.5425e-01, -1.4687e-01, -2.4593e-01, -1.0440e-01, -1.0440e-01,\n",
      "         -1.1341e-01],\n",
      "        [ 2.6415e-01, -1.3681e-03, -2.2124e-01, -3.8273e-02, -1.4698e-01,\n",
      "          1.2867e-02],\n",
      "        [ 1.8833e-01, -1.6766e-01, -2.5178e-01, -4.5637e-02, -1.1507e-01,\n",
      "         -8.3059e-02]], grad_fn=<AddmmBackward0>))\n",
      "torch.Size([8047]) torch.Size([2, 158700]) torch.Size([158700, 7]) torch.Size([8047])\n",
      "(tensor([[ 0.5101,  0.0271,  0.8408,  ..., -0.1066,  0.3179, -0.6624],\n",
      "        [ 0.9980,  0.1096,  2.3186,  ...,  0.4457,  3.1102, -1.3077],\n",
      "        [-0.1430,  0.4149, -0.3825,  ..., -0.2358, -0.3620, -0.6275],\n",
      "        ...,\n",
      "        [ 1.1834,  1.1666,  0.2616,  ...,  1.1639, -0.9871,  1.2219],\n",
      "        [-0.3890, -0.4447,  2.2822,  ...,  0.6725, -0.4230,  0.2060],\n",
      "        [ 0.8287,  0.1500, -0.3832,  ..., -0.1922,  0.0703,  0.4410]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0938, -0.0259,  0.0606,  ...,  0.0843,  0.1441,  0.0192],\n",
      "        [ 0.1748, -0.0132,  0.0455,  ...,  0.4198,  0.7713, -0.5039],\n",
      "        [ 0.0425,  0.0012,  0.0448,  ...,  0.1153,  0.2324, -0.0819],\n",
      "        ...,\n",
      "        [ 0.0866, -0.0548,  0.0221,  ...,  0.1602, -0.0107, -0.0210],\n",
      "        [ 0.0940, -0.0627,  0.0231,  ...,  0.1699, -0.0152, -0.0225],\n",
      "        [ 0.1011, -0.0732,  0.0255,  ...,  0.1787, -0.0187, -0.0347]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0403,  0.0217,  0.1055,  ...,  0.1045, -0.0626,  0.0480],\n",
      "        [ 0.3729, -0.5631,  0.0970,  ...,  0.1315, -0.3322,  0.4603],\n",
      "        [ 0.0414, -0.0628,  0.0219,  ...,  0.0849, -0.0250,  0.0905],\n",
      "        ...,\n",
      "        [-0.0443, -0.0120, -0.0373,  ...,  0.0969, -0.0760,  0.0522],\n",
      "        [-0.0481, -0.0158, -0.0298,  ...,  0.1040, -0.0748,  0.0646],\n",
      "        [-0.0429, -0.0171, -0.0232,  ...,  0.1060, -0.0754,  0.0803]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.2617, -0.1188, -0.2530, -0.1449, -0.0999, -0.0814],\n",
      "        [ 0.1878, -0.1009, -0.2469, -0.1026, -0.1446, -0.0860],\n",
      "        [ 0.2497, -0.0433, -0.2885, -0.1283, -0.1618, -0.0592],\n",
      "        [ 0.2094, -0.0790, -0.2351, -0.0218, -0.1449, -0.0857],\n",
      "        [ 0.2374, -0.1012, -0.2029, -0.0160, -0.1145, -0.0692],\n",
      "        [ 0.1247, -0.1030, -0.2423, -0.1557, -0.1849, -0.0458],\n",
      "        [ 0.2162, -0.0913, -0.2852, -0.1715, -0.1119, -0.0143],\n",
      "        [ 0.2162, -0.1130, -0.2605, -0.1215, -0.1596, -0.0899],\n",
      "        [ 0.2916, -0.1153, -0.3033, -0.0778, -0.1004, -0.0865],\n",
      "        [ 0.2318, -0.0511, -0.2563, -0.1678, -0.1055, -0.0816],\n",
      "        [ 0.2605, -0.0683, -0.2108, -0.0668, -0.0688, -0.0848],\n",
      "        [ 0.1957, -0.1278, -0.2668, -0.1100, -0.1230, -0.0459],\n",
      "        [ 0.1904, -0.1726, -0.3060, -0.1551, -0.0511, -0.0105],\n",
      "        [ 0.2875, -0.1968, -0.2367, -0.0893, -0.1822, -0.0797],\n",
      "        [ 0.2013, -0.2032, -0.1973, -0.0496, -0.3738, -0.1350],\n",
      "        [ 0.2117, -0.0527, -0.2538, -0.2288, -0.1232, -0.1287],\n",
      "        [ 0.2811, -0.1530, -0.2994, -0.0806, -0.1214, -0.0462],\n",
      "        [ 0.2245, -0.0290, -0.2244, -0.0710, -0.0604, -0.1524],\n",
      "        [ 0.2853, -0.1905, -0.2939, -0.1160, -0.1621, -0.0019],\n",
      "        [ 0.2294, -0.1268, -0.2391, -0.0388, -0.0860, -0.0477],\n",
      "        [ 0.2189, -0.0594, -0.2267, -0.0882, -0.1228,  0.0031],\n",
      "        [ 0.2230, -0.1602, -0.2795, -0.0932, -0.0650, -0.0975],\n",
      "        [ 0.2255, -0.0775, -0.2766, -0.1606, -0.1359, -0.1053],\n",
      "        [ 0.2846, -0.1946, -0.2604, -0.0544, -0.1319, -0.0654],\n",
      "        [ 0.2605, -0.1070, -0.2810, -0.1206, -0.1342, -0.0780],\n",
      "        [ 0.2003, -0.0922, -0.2449, -0.1082, -0.1034, -0.0390],\n",
      "        [ 0.3732, -0.1155, -0.2754, -0.0574, -0.2570, -0.0575],\n",
      "        [ 0.2042, -0.1525, -0.2455, -0.1139, -0.1573, -0.0477],\n",
      "        [ 0.1319,  0.0053, -0.3118, -0.1819, -0.0028, -0.0310],\n",
      "        [ 0.2155, -0.1169, -0.4265, -0.2937,  0.0613, -0.1061],\n",
      "        [ 0.3086, -0.1261, -0.2838, -0.0955, -0.0864, -0.0414],\n",
      "        [ 0.2292, -0.1119, -0.3480, -0.1436, -0.0775, -0.0999]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7752]) torch.Size([2, 150696]) torch.Size([150696, 7]) torch.Size([7752])\n",
      "(tensor([[ 0.1425,  0.7768,  1.4301,  ..., -0.1018, -0.1205, -1.4984],\n",
      "        [-2.0100,  0.5627,  0.1280,  ...,  0.8308, -0.1163, -2.5150],\n",
      "        [-0.5183,  0.0230, -1.7602,  ...,  0.5199,  0.2900,  1.2096],\n",
      "        ...,\n",
      "        [ 1.1375, -0.3853,  1.2113,  ..., -0.0179, -0.9663,  0.5563],\n",
      "        [-0.7819, -0.9473,  0.5679,  ..., -0.2252, -0.0914, -1.7800],\n",
      "        [ 1.6221,  0.3675, -1.3829,  ..., -0.4273,  0.2795, -1.3697]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0492, -0.0666,  0.0414,  ...,  0.1561,  0.0185, -0.0222],\n",
      "        [ 0.1863,  0.1348, -0.0444,  ...,  0.4461,  0.0011, -0.1499],\n",
      "        [ 0.0171, -0.0595,  0.0478,  ...,  0.1434,  0.0427,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0890, -0.0703,  0.0237,  ...,  0.1914, -0.0277, -0.0266],\n",
      "        [ 0.0886, -0.0689,  0.0302,  ...,  0.1914, -0.0264, -0.0261],\n",
      "        [ 0.0903, -0.0713,  0.0256,  ...,  0.1910, -0.0295, -0.0269]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0250, -0.0135, -0.0255,  ...,  0.0688, -0.0635,  0.0521],\n",
      "        [ 0.0605, -0.1642, -0.1971,  ...,  0.1654, -0.1076, -0.0247],\n",
      "        [-0.0160, -0.0281, -0.0033,  ...,  0.0453, -0.0591,  0.0284],\n",
      "        ...,\n",
      "        [-0.0453, -0.0271, -0.0221,  ...,  0.1030, -0.0692,  0.0745],\n",
      "        [-0.0447, -0.0312, -0.0222,  ...,  0.1036, -0.0718,  0.0694],\n",
      "        [-0.0465, -0.0285, -0.0224,  ...,  0.1044, -0.0695,  0.0754]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 2.1138e-01, -1.2413e-01, -2.5663e-01, -1.2421e-01, -1.9276e-01,\n",
      "         -3.6630e-02],\n",
      "        [ 2.2632e-01, -1.3583e-01, -2.6050e-01, -1.1290e-01, -1.7654e-01,\n",
      "         -5.8888e-02],\n",
      "        [ 2.6957e-01,  8.9650e-02, -2.9807e-01, -4.9287e-02, -5.7807e-02,\n",
      "         -5.9178e-02],\n",
      "        [ 2.3177e-01, -1.0804e-01, -2.2540e-01, -1.2935e-01, -2.0742e-01,\n",
      "         -5.1209e-02],\n",
      "        [ 2.0131e-01, -9.8366e-02, -2.6592e-01, -1.4771e-01, -5.6026e-02,\n",
      "         -7.7482e-02],\n",
      "        [ 3.3315e-02, -1.2825e-01, -4.6292e-01, -4.3756e-01,  1.2837e-01,\n",
      "          7.1560e-03],\n",
      "        [ 2.5848e-01, -1.9552e-01, -2.8411e-01, -1.3718e-01, -4.6385e-02,\n",
      "         -1.0682e-01],\n",
      "        [ 2.3420e-01, -9.9270e-02, -3.0636e-01, -1.0866e-01, -8.1273e-02,\n",
      "         -8.2532e-02],\n",
      "        [ 2.2889e-01, -1.5442e-01, -3.0857e-01, -1.5833e-01, -1.6310e-01,\n",
      "         -6.1502e-02],\n",
      "        [ 5.4049e-01, -2.2616e-01, -3.7248e-01, -3.3716e-02, -5.7983e-02,\n",
      "         -9.3178e-02],\n",
      "        [ 2.8614e-01, -1.5739e-01, -1.5054e-01, -6.3966e-02, -2.1219e-01,\n",
      "         -1.5092e-01],\n",
      "        [ 2.3619e-01, -1.4414e-01, -2.1231e-01, -7.4921e-02, -1.1038e-01,\n",
      "         -1.1361e-01],\n",
      "        [ 2.4707e-01, -1.1555e-01, -3.2655e-01, -1.9631e-01,  1.8313e-02,\n",
      "         -4.0068e-02],\n",
      "        [ 2.0919e-01, -8.5729e-02, -2.8113e-01, -1.2466e-01, -1.3458e-01,\n",
      "         -9.7629e-02],\n",
      "        [ 2.2217e-01, -1.4344e-01, -2.8033e-01, -1.5473e-01, -1.0626e-01,\n",
      "         -1.0259e-01],\n",
      "        [ 2.4455e-01, -1.2825e-01, -2.7057e-01, -7.1043e-02, -1.5251e-01,\n",
      "         -5.0405e-02],\n",
      "        [ 2.2959e-01, -1.2003e-01, -1.7748e-01, -8.0919e-02, -1.8285e-01,\n",
      "         -7.3455e-02],\n",
      "        [ 2.8268e-01, -2.1197e-01, -2.5426e-01,  2.4048e-02, -1.6850e-01,\n",
      "         -1.0747e-01],\n",
      "        [ 2.4155e-01, -1.4178e-01, -2.9334e-01, -9.1937e-02, -1.3625e-01,\n",
      "         -8.2300e-02],\n",
      "        [ 1.9657e-01, -1.5753e-01, -3.0978e-01, -1.3983e-01, -9.4990e-02,\n",
      "         -4.1755e-02],\n",
      "        [ 2.4608e-01, -1.3325e-01, -2.4901e-01, -1.0817e-01, -1.3853e-01,\n",
      "         -6.5916e-02],\n",
      "        [ 2.1145e-01, -1.1585e-01, -2.6281e-01, -1.3013e-01, -1.2739e-01,\n",
      "         -9.3553e-02],\n",
      "        [ 2.4205e-01, -1.4325e-01, -2.8247e-01, -1.4482e-01, -1.6674e-01,\n",
      "         -7.7684e-02],\n",
      "        [ 3.0382e-01, -1.8092e-01, -2.5672e-01, -1.2613e-01, -2.0517e-01,\n",
      "         -5.4482e-02],\n",
      "        [ 2.0101e-01, -1.0759e-01, -2.6766e-01, -1.6860e-01, -1.5494e-01,\n",
      "         -2.9122e-02],\n",
      "        [ 1.1067e-01,  1.4488e-03, -2.7385e-01, -2.0588e-01, -6.4164e-05,\n",
      "         -1.0957e-01],\n",
      "        [ 1.9972e-01, -8.8776e-02, -2.3296e-01, -9.8120e-02, -1.8365e-01,\n",
      "         -4.1904e-02],\n",
      "        [ 2.1453e-01, -6.4540e-02, -2.6475e-01, -1.2971e-01, -1.2754e-01,\n",
      "         -6.3714e-02],\n",
      "        [ 1.1914e-01, -8.1808e-02, -2.6119e-01, -1.2231e-01, -2.3063e-01,\n",
      "          3.8053e-02],\n",
      "        [ 1.7484e-01, -1.3305e-01, -3.2475e-01, -2.0811e-01, -1.3873e-02,\n",
      "         -2.5444e-02],\n",
      "        [ 2.2074e-01, -1.2971e-01, -3.0418e-01, -1.2304e-01, -1.6441e-01,\n",
      "         -7.3428e-02],\n",
      "        [ 1.7383e-01, -8.6037e-02, -3.3690e-01, -9.6688e-02, -1.2973e-01,\n",
      "         -9.2018e-02]], grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7758]) torch.Size([2, 135108]) torch.Size([135108, 7]) torch.Size([7758])\n",
      "(tensor([[ 0.6177, -1.8782,  0.3728,  ...,  0.1478, -0.1894,  0.2523],\n",
      "        [ 0.6649, -0.2168,  2.4176,  ...,  0.1732, -0.0052, -1.1492],\n",
      "        [-0.0360,  2.5785, -0.4643,  ...,  0.9258,  0.5459,  0.3790],\n",
      "        ...,\n",
      "        [-0.5136,  1.8520,  0.6448,  ..., -2.0963,  0.6933,  1.4714],\n",
      "        [ 0.8246,  1.5297,  0.0966,  ...,  1.2634,  0.4195,  0.0731],\n",
      "        [ 0.1243, -0.1370, -0.4163,  ..., -1.2490,  0.4850, -2.0976]],\n",
      "       grad_fn=<AddBackward0>), tensor([[ 0.0641, -0.0934,  0.0201,  ...,  0.1294,  0.0196, -0.0236],\n",
      "        [ 0.0465, -0.0798,  0.0226,  ...,  0.1306,  0.0343, -0.0065],\n",
      "        [ 0.1935, -0.0817, -0.0345,  ...,  0.0937,  0.0736, -0.1063],\n",
      "        ...,\n",
      "        [ 0.0949, -0.0818,  0.0246,  ...,  0.1679, -0.0126, -0.0360],\n",
      "        [ 0.0931, -0.0730,  0.0282,  ...,  0.1763, -0.0179, -0.0287],\n",
      "        [ 0.0488, -0.0687,  0.0214,  ...,  0.1559,  0.0074, -0.0347]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.0253,  0.0063, -0.0249,  ...,  0.0805, -0.0373,  0.0646],\n",
      "        [-0.0149,  0.0056, -0.0179,  ...,  0.0568, -0.0273,  0.0384],\n",
      "        [ 0.0754, -0.0159, -0.0069,  ...,  0.0550, -0.0825,  0.0015],\n",
      "        ...,\n",
      "        [-0.0412, -0.0117, -0.0242,  ...,  0.0938, -0.0574,  0.0820],\n",
      "        [-0.0439, -0.0188, -0.0239,  ...,  0.0900, -0.0644,  0.0725],\n",
      "        [-0.0815, -0.0191,  0.0806,  ...,  0.0706, -0.1012,  0.0566]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[ 0.1911, -0.0952, -0.2480, -0.0370, -0.1461, -0.0979],\n",
      "        [ 0.3008, -0.1896, -0.2896, -0.1061, -0.1075, -0.0201],\n",
      "        [ 0.1938, -0.1030, -0.2918, -0.0172, -0.1387, -0.0602],\n",
      "        [ 0.1967, -0.2008, -0.3510, -0.2077,  0.0267, -0.0965],\n",
      "        [ 0.2516, -0.0842, -0.2708, -0.0669, -0.1289, -0.0074],\n",
      "        [ 0.1635, -0.1403, -0.2626, -0.2022, -0.2018, -0.0224],\n",
      "        [ 0.2330, -0.0864, -0.2335, -0.1211, -0.1266, -0.0771],\n",
      "        [ 0.1735, -0.1548, -0.2212, -0.0207, -0.1573, -0.0561],\n",
      "        [ 0.2001, -0.0954, -0.2353, -0.1317, -0.1271, -0.0871],\n",
      "        [ 0.2286, -0.1010, -0.2931, -0.1496, -0.1235, -0.0676],\n",
      "        [ 0.2173, -0.1687, -0.2464, -0.0933, -0.1446, -0.0738],\n",
      "        [ 0.2189, -0.0961, -0.2532, -0.0989, -0.1386, -0.0756],\n",
      "        [ 0.1508, -0.2556, -0.2067, -0.0725, -0.1527, -0.1183],\n",
      "        [ 0.1390, -0.1564, -0.2684, -0.1976, -0.1919, -0.0890],\n",
      "        [ 0.2049, -0.1383, -0.2812, -0.1587, -0.2090, -0.0514],\n",
      "        [ 0.1974, -0.0868, -0.2813, -0.2132, -0.1041, -0.0409],\n",
      "        [ 0.2278, -0.1374, -0.3013, -0.0980, -0.1353, -0.1104],\n",
      "        [ 0.2029, -0.1553, -0.2881, -0.1361, -0.1302, -0.0415],\n",
      "        [ 0.2917, -0.1338, -0.2915, -0.0380, -0.0688, -0.0716],\n",
      "        [ 0.1685, -0.1569, -0.2825, -0.1448, -0.1412, -0.0775],\n",
      "        [ 0.2456, -0.1290, -0.2322, -0.0967, -0.1044, -0.0761],\n",
      "        [ 0.2687, -0.1687, -0.2920, -0.0916, -0.1437, -0.0346],\n",
      "        [ 0.2522, -0.1115, -0.2354, -0.0689, -0.1461, -0.0685],\n",
      "        [ 0.2605, -0.1048, -0.2450, -0.1260, -0.1088, -0.0651],\n",
      "        [ 0.1935, -0.1662, -0.3290, -0.2747, -0.1082,  0.0271],\n",
      "        [ 0.2355, -0.1753, -0.2332, -0.1089, -0.1151, -0.0630],\n",
      "        [ 0.2095, -0.1768, -0.2346, -0.0598, -0.1654, -0.0796],\n",
      "        [ 0.1969, -0.0732, -0.2192,  0.0357, -0.0550, -0.0375],\n",
      "        [ 0.2185, -0.0711, -0.2898, -0.0908, -0.1486, -0.0611],\n",
      "        [ 0.2798, -0.1081, -0.2548, -0.1125, -0.1319, -0.0501],\n",
      "        [ 0.2278, -0.1097, -0.3156, -0.1298, -0.1449, -0.0669],\n",
      "        [ 0.1527,  0.0358, -0.3491, -0.2658,  0.1130, -0.0935]],\n",
      "       grad_fn=<AddmmBackward0>))\n",
      "torch.Size([7866]) torch.Size([2, 163478]) torch.Size([163478, 7]) torch.Size([7866])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 92\u001b[0m\n\u001b[1;32m     90\u001b[0m model \u001b[38;5;241m=\u001b[39m VGAE(\u001b[38;5;241m1\u001b[39m, edge_attr_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 92\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 56\u001b[0m, in \u001b[0;36mVGAE.forward\u001b[0;34m(self, data, inference)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# x = torch.ones()\u001b[39;00m\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 56\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inference:\n\u001b[1;32m     58\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, logvar)\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mVGAE_MessagePassing.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_attr))\n\u001b[1;32m     27\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu_layer(x)\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/src/conv.py:25\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[1;32m     24\u001b[0m     edge_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps) \u001b[38;5;241m*\u001b[39mx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_embedding\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/tmp/src.conv_GINConv_propagate_eitcrg1p.py:183\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    174\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    175\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[1;32m    180\u001b[0m             )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/src/conv.py:30\u001b[0m, in \u001b[0;36mGINConv.message\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j, edge_attr):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UNI/DeepLearning/hackaton/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from src.conv import GINConv\n",
    "\n",
    "class VGAE_MessagePassing(nn.Module):\n",
    "    def __init__(self, in_channels, edge_attr_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        # Edge network to produce convolution weights from edge attributes        \n",
    "        self.conv1 = GINConv(hidden_dim)\n",
    "        self.conv2 = GINConv(hidden_dim)\n",
    "\n",
    "        self.mu_layer = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar_layer = torch.nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.edge_attr_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, edge_attr_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "\n",
    "        mu = self.mu_layer(x)\n",
    "        logvar = self.logvar_layer(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class VGAE(nn.Module):\n",
    "    def __init__(self, in_channels, edge_attr_dim, hidden_dim, latent_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = VGAE_MessagePassing(in_channels, edge_attr_dim, hidden_dim, latent_dim)\n",
    "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        adj_pred = torch.sigmoid(torch.mm(z, z.t()))\n",
    "        \n",
    "        edge_feat_input = torch.cat([z[edge_index[0]], z[edge_index[1]]], dim=1)\n",
    "        edge_attr_pred = torch.sigmoid(self.edge_attr_decoder(edge_feat_input))\n",
    "        \n",
    "        return adj_pred, edge_attr_pred\n",
    "\n",
    "    def forward(self, data, inference=False):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        print(x.shape, edge_index.shape, edge_attr.shape, batch.shape)\n",
    "        # x = torch.ones()\n",
    "        x = x.reshape((-1, 1))\n",
    "        mu, logvar = self.encoder(x, edge_index, edge_attr)\n",
    "        if not inference:\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Graph-level embedding via mean pooling of latent node embeddings\n",
    "        graph_emb = global_mean_pool(z, batch)\n",
    "        class_logits= self.classifier(graph_emb)\n",
    "        return z, mu, logvar, class_logits\n",
    "    \n",
    "    def loss(self, z, mu, logvar, class_logits, data, alpha=1, beta=0.1, gamma=0.1, delta=0.1):\n",
    "        classification_loss = F.cross_entropy(class_logits, data.y)\n",
    "\n",
    "        adj_pred, edge_attr_pred = self.decode(z, data.edge_index)\n",
    "        adj_true = torch.zeros_like(adj_pred)\n",
    "        adj_true[data.edge_index[0], data.edge_index[1]]\n",
    "\n",
    "        adj_loss = F.binary_cross_entropy(adj_pred, adj_true)\n",
    "        edge_attr_loss = F.mse_loss(edge_attr_pred, data.edge_attr)\n",
    "\n",
    "        kl_loss = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "        loss = (\n",
    "            alpha * classification_loss +\n",
    "            beta * adj_loss +\n",
    "            gamma * edge_attr_loss +\n",
    "            delta * kl_loss\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = VGAE(1, edge_attr_dim=7, hidden_dim=128, latent_dim=16, num_classes=6)\n",
    "for data in train_loader:\n",
    "    res = model(data)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32afff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCELoss(nn.Module):\n",
    "    def __init__(self, q=0.7, smoothing=0.1, temperature=2.0, num_classes=6):\n",
    "        \"\"\"\n",
    "        Generalized Cross Entropy Loss\n",
    "        Args:\n",
    "            q: exponent hyperparameter, controls sensitivity to noise. 0.7 is a good default.\n",
    "            num_classes: number of classes in your classification problem.\n",
    "            reduction: 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        super(GCELoss, self).__init__()\n",
    "        assert q > 0 and q <= 1, \"q should be in (0, 1]\"\n",
    "        self.q = q\n",
    "        self.num_classes = num_classes\n",
    "        self.smoothing = smoothing\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, logits, targets, reduction=\"mean\"):\n",
    "        \"\"\"\n",
    "        logits: [batch_size, num_classes] (raw output from the model)\n",
    "        targets: [batch_size] (ground-truth labels)\n",
    "        \"\"\"\n",
    "        probs = F.softmax(logits / self.temperature, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "        targets_one_hot = (1 - self.smoothing) * targets_one_hot + self.smoothing / self.num_classes\n",
    "\n",
    "        # Get p_y^q for each sample\n",
    "        pt = (probs * targets_one_hot).sum(dim=1)\n",
    "        loss = (1 - pt ** self.q) / self.q\n",
    "\n",
    "        if reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "class EntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.softmax(x, dim=1)\n",
    "        x = x.mean(dim=0)\n",
    "        return -(x * torch.log(x + 1e-6)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d33b8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_and_preds(dataloader, embedding_model, classifier, device='cuda'):\n",
    "    embedding_model.eval();  classifier.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_pred_probs = []\n",
    "    original_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            data = data.to(device)\n",
    "            emb = embedding_model(data) \n",
    "            logits = classifier(emb)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "            all_embeddings.append(emb.cpu())\n",
    "            all_pred_probs.append(probs.cpu())\n",
    "            original_labels.append(data.cpu().y)\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    all_pred_probs = torch.cat(all_pred_probs, dim=0) \n",
    "    original_labels = torch.cat(original_labels, dim=0)\n",
    "\n",
    "    return all_embeddings, all_pred_probs, original_labels\n",
    "\n",
    "def neighbor_aware_label_correction(embeddings, pred_probs, original_labels, mu=0.8, K=5, delta_prime=0.9, c=1, cmax=10, tau=0.5):\n",
    "    print(f\"Avg max pred {pred_probs.max(dim=1).values.mean().item()}\")\n",
    "    emb_norm = F.normalize(embeddings, p=2, dim=1) \n",
    "    sim_matrix = torch.mm(emb_norm, emb_norm.T) \n",
    "    sim_matrix = torch.exp(sim_matrix / tau) \n",
    "\n",
    "    topk_vals, topk_idx = torch.topk(sim_matrix, K+1, dim=1)\n",
    "    topk_vals = topk_vals[:, 1:] \n",
    "    topk_idx = topk_idx[:, 1:]\n",
    "\n",
    "\n",
    "    neighbors_preds = pred_probs[topk_idx] \n",
    "    weights = topk_vals / topk_vals.sum(dim=1, keepdim=True)\n",
    "    weighted_neighbors_preds = (weights.unsqueeze(2) * neighbors_preds).sum(dim=1)\n",
    "    qi = mu * pred_probs + (1 - mu) * weighted_neighbors_preds  \n",
    "    print(f\"Avg qi {qi.max(dim=1).values.mean().item()}\")\n",
    "\n",
    "    delta_c = delta_prime * (c / cmax)\n",
    "    qi_max_class = qi.argmax(dim=1)\n",
    "\n",
    "    clean_mask = (qi_max_class == original_labels)  \n",
    "    max_qi_vals, _ = qi.max(dim=1)\n",
    "    confident_mask = max_qi_vals > delta_c\n",
    "    print(f\"Updating {((confident_mask & (~clean_mask))*1.0).mean()} of the labels\")\n",
    "    updated_mask = clean_mask | confident_mask\n",
    "    new_labels = torch.where(clean_mask, original_labels, qi_max_class)\n",
    "\n",
    "    return updated_mask, new_labels, qi\n",
    "\n",
    "def filter_dataset_with_label_correction(train_dataset, updated_mask, new_labels):\n",
    "    filtered_dataset = []\n",
    "    for i, sample in tqdm(enumerate(train_dataset)):\n",
    "        if updated_mask[i].item():\n",
    "            sample.y = new_labels[i].unsqueeze(0) \n",
    "            filtered_dataset.append(sample)\n",
    "    return filtered_dataset\n",
    "\n",
    "def add_signed_noise(h, gamma=0.01):\n",
    "    raw_noise = torch.randn_like(h)\n",
    "    normed_noise = F.normalize(raw_noise, p=2, dim=1)\n",
    "    scaled_noise = gamma * normed_noise\n",
    "    signed_noise = torch.abs(scaled_noise) * torch.sign(h)\n",
    "    return h + signed_noise\n",
    "\n",
    "\n",
    "def mixup_embeddings(embeddings, labels, alpha=0.1, beta=0.1):\n",
    "    batch_size = embeddings.size(0)\n",
    "    device = embeddings.device\n",
    "    lam = torch.distributions.Beta(alpha, beta).sample([batch_size]).to(device).view(-1, 1)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "    mixed_embeddings = lam * embeddings + (1 - lam) * embeddings[index]\n",
    "    mixed_labels = lam * labels + (1 - lam) * labels[index]\n",
    "    return mixed_embeddings, mixed_labels\n",
    "\n",
    "def get_positive_mask(mixed_labels, threshold=0.05):\n",
    "    diff = mixed_labels.unsqueeze(1) - mixed_labels.unsqueeze(0)\n",
    "    l2_dist = torch.norm(diff, p=2, dim=2)\n",
    "    pos_mask = (l2_dist < threshold).float()\n",
    "    pos_mask.fill_diagonal_(0.0) \n",
    "    return pos_mask\n",
    "\n",
    "def get_negatives(z):\n",
    "    z_norm = F.normalize(z, p=2, dim=1)\n",
    "    cosine_sim = torch.matmul(z_norm, z_norm.T) \n",
    "    mask = 1.0 - torch.eye(z.size(0), device=z.device)\n",
    "    masked_sim = cosine_sim.masked_fill(mask == 0, float('-inf'))\n",
    "    weights = F.softmax(masked_sim, dim=1)\n",
    "    soft_negatives = torch.matmul(weights, z)\n",
    "    return soft_negatives\n",
    "\n",
    "class OmgContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OmgContrastiveLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, positive_mask, neg):\n",
    "        pred = F.normalize(pred, dim=1)\n",
    "        neg = F.normalize(neg, dim=1)\n",
    "\n",
    "        dists = torch.norm(pred.unsqueeze(1) - pred.unsqueeze(0), p=2, dim=2)\n",
    "        pos_sum = (dists * positive_mask).sum(dim=1) \n",
    "        pos_counts = torch.clamp(positive_mask.sum(dim=1), min=1.0)\n",
    "        pos_avg = pos_sum / pos_counts\n",
    "\n",
    "        neg_dists = torch.norm(pred - neg, p=2, dim=1)  \n",
    "\n",
    "        # print(pos_avg.sum().item(), neg_dists.sum().item())\n",
    "        loss_per_sample = pos_avg - neg_dists\n",
    "        return loss_per_sample.mean()\n",
    "\n",
    "class SupervisedSoftLabelLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SupervisedSoftLabelLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_pred):\n",
    "        log_probs = F.log_softmax(y_pred, dim=1)\n",
    "        loss = -(y*log_probs).sum(dim=1).mean() \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9cbdcc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "\n",
    "\n",
    "num_layer = 3\n",
    "emb_dim = 64\n",
    "drop_ratio = 0.5\n",
    "num_epochs = 5\n",
    "warm_up_epochs = 10\n",
    "device = \"cuda:0\"\n",
    "script_dir = \"./\"\n",
    "num_checkpoints = 5\n",
    "num_class = 6\n",
    "\n",
    "embedding_model = GNN(gnn_type=\"gin\", num_class=num_class, num_layer = num_layer, emb_dim = emb_dim, drop_ratio = drop_ratio, graph_pooling = \"mean\").to(device)\n",
    "embedding_projector = MLP([emb_dim, 32, 16]).to(device)\n",
    "classifier = MLP([emb_dim, num_class]).to(device)\n",
    "model = CompleteModel(embedding_model, classifier)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "contrastive_optimizer = torch.optim.Adam(list(embedding_model.parameters()) + list(embedding_projector.parameters()) + list(classifier.parameters()), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "contrastive_loss = OmgContrastiveLoss()\n",
    "supervised_label_loss = SupervisedSoftLabelLoss()\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ff61c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 18.31it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -0.7829, Train Acc: 0.3594\n",
      "Pred distribution: [0.11380208283662796, 0.14049479365348816, 0.6451823115348816, 0.04401041567325592, 0.005078124813735485, 0.0514322929084301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.67it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: -0.8029, Train Acc: 0.1803\n",
      "Pred distribution: [0.4455729126930237, 0.23033854365348816, 0.15078124403953552, 0.15026041865348816, 0.0005208333604969084, 0.02252604253590107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.72it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: -0.8192, Train Acc: 0.1743\n",
      "Pred distribution: [0.0054687499068677425, 0.12708333134651184, 0.19700521230697632, 0.009244791232049465, 0.04843749850988388, 0.6127604246139526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.72it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: -0.8305, Train Acc: 0.1428\n",
      "Pred distribution: [0.4123697876930237, 0.15781250596046448, 0.1087239608168602, 0.2652343809604645, 0.0403645820915699, 0.01549479179084301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.48it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: -0.8390, Train Acc: 0.1711\n",
      "Pred distribution: [0.359375, 0.2808593809604645, 0.07135416567325592, 0.23736979067325592, 0.03697916492819786, 0.01406249962747097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.62it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: -0.8447, Train Acc: 0.3257\n",
      "Pred distribution: [0.04830729216337204, 0.25924479961395264, 0.22643229365348816, 0.10820312798023224, 0.07109375298023224, 0.2867187559604645]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.29it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: -0.8571, Train Acc: 0.2706\n",
      "Pred distribution: [0.24908854067325592, 0.23046875, 0.13854166865348816, 0.22604165971279144, 0.0572916679084301, 0.09856770932674408]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.44it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: -0.8634, Train Acc: 0.3418\n",
      "Pred distribution: [0.041015625, 0.19869790971279144, 0.2604166567325592, 0.0559895820915699, 0.06549479067325592, 0.37838542461395264]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.53it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: -0.8767, Train Acc: 0.0960\n",
      "Pred distribution: [0.7755208611488342, 0.02291666716337204, 0.03281249850988388, 0.12708333134651184, 0.02903645858168602, 0.012630208395421505]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.45it/s]\n",
      "100%|██████████| 240/240 [00:12<00:00, 19.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: -0.8806, Train Acc: 0.4286\n",
      "Pred distribution: [0.06145833432674408, 0.09934895485639572, 0.5854166746139526, 0.11861979216337204, 0.04869791492819786, 0.08645833283662796]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion1 = GCELoss(q=0.7, num_classes=num_class)\n",
    "criterion2 = EntropyLoss()\n",
    "\n",
    "for epoch in range(warm_up_epochs):\n",
    "    model.train(); embedding_projector.train()\n",
    "    total_loss = 0.0\n",
    "    for data in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        loss1, loss2 = criterion1(logits, data.y), criterion2(logits)\n",
    "        # print(logits)\n",
    "        # print(F.one_hot(logits.argmax(dim=1), num_classes=num_class).float().cpu().mean(dim=0), loss1, loss2)\n",
    "        loss = loss1 - loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    total_loss = total_loss / len(train_loader)\n",
    "    model.eval();  embedding_projector.eval()\n",
    "    p_dist = torch.zeros((num_class, ))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            p_dist += F.one_hot(pred, num_classes=num_class).float().cpu().mean(dim=0)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{warm_up_epochs}, Loss: {total_loss:.4f}, Train Acc: {accuracy:.4f}\")\n",
    "    print(f\"Pred distribution: {(p_dist / len(train_loader)).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe603221",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./develop_checkpoint/warmup_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44001671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = GNN(gnn_type=\"gin\", num_class=num_class, num_layer = num_layer, emb_dim = emb_dim, drop_ratio = drop_ratio, graph_pooling = \"mean\").to(device)\n",
    "embedding_projector = MLP([emb_dim, 32, 16]).to(device)\n",
    "classifier = MLP([emb_dim, num_class]).to(device)\n",
    "model = CompleteModel(embedding_model, classifier)\n",
    "model.load_state_dict(torch.load(\"./develop_checkpoint/warmup_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b7f5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.05\n",
    "\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "filtered_train_dataset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33f88876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.75it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 184.4079, Train Acc: 0.4576\n",
      "Pred distribution: [0.02356770820915699, 0.39049479365348816, 0.26249998807907104, 0.02174479141831398, 0.02317708358168602, 0.27851563692092896]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.46it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 176.3153, Train Acc: 0.6654\n",
      "Pred distribution: [0.10208333283662796, 0.2727864682674408, 0.4216145873069763, 0.10078124701976776, 0.009114583022892475, 0.09361979365348816]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.63it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 173.9217, Train Acc: 0.7362\n",
      "Pred distribution: [0.0377604179084301, 0.19934895634651184, 0.5625, 0.07369791716337204, 0.05820312350988388, 0.06848958134651184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:14<00:00, 16.92it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 174.8986, Train Acc: 0.7312\n",
      "Pred distribution: [0.04374999925494194, 0.1744791716337204, 0.5354166626930237, 0.10533854365348816, 0.07434895634651184, 0.06666667014360428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:13<00:00, 17.52it/s]\n",
      "100%|██████████| 240/240 [00:11<00:00, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 175.0320, Train Acc: 0.7453\n",
      "Pred distribution: [0.05429687350988388, 0.24700520932674408, 0.46601563692092896, 0.09648437798023224, 0.03789062425494194, 0.0983072891831398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_max = 1\n",
    "for c in range(c_max):\n",
    "    filtered_train_loader = DataLoader(filtered_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # embeddings, pred_probs, original_labels = compute_embeddings_and_preds(filtered_train_loader, embedding_model, classifier)\n",
    "    # updated_mask, new_labels, _ = neighbor_aware_label_correction(embeddings, pred_probs, original_labels, c=c, cmax=c_max, K=10, mu=0.8)\n",
    "    # print(f\"Keeping {(updated_mask*1.).mean()} of previous data\")\n",
    "    # filtered_train_dataset = filter_dataset_with_label_correction(filtered_train_dataset, updated_mask, new_labels)\n",
    "    # filtered_train_loader = DataLoader(filtered_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs): \n",
    "        embedding_model.train();  embedding_projector.train(); classifier.train()\n",
    "        total_loss = 0.0\n",
    "        for data in tqdm(filtered_train_loader):\n",
    "            contrastive_optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            label = F.one_hot(data.y, num_classes=num_class).float()\n",
    "            embeddings = embedding_model(data)\n",
    "            embeddings = add_signed_noise(embeddings)\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            z, y = mixup_embeddings(embeddings, label)\n",
    "            positive_mask = get_positive_mask(y)\n",
    "            negatives = get_negatives(z)\n",
    "\n",
    "            emb_proj, neg_proj = embedding_projector(z), embedding_projector(negatives)\n",
    "            y_pred = classifier(z)\n",
    "            cl_loss, sup_loss = contrastive_loss(emb_proj, positive_mask, neg_proj), supervised_label_loss(y, y_pred)\n",
    "            loss = beta * cl_loss + sup_loss\n",
    "            # print(cl_loss, sup_loss)\n",
    "            loss.backward()\n",
    "            contrastive_optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        embedding_model.eval();  classifier.eval(); embedding_projector.train()\n",
    "        p_dist = torch.zeros((num_class, ))\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in tqdm(train_loader):\n",
    "                data = data.to(device)\n",
    "                output = embedding_model(data)\n",
    "                output = F.normalize(output, p=2, dim=1)\n",
    "                pred = classifier(output)\n",
    "                pred = pred.argmax(dim=1)\n",
    "                p_dist += F.one_hot(pred, num_classes=num_class).float().cpu().mean(dim=0)\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "            accuracy = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}, Train Acc: {accuracy:.4f}\")\n",
    "        print(f\"Pred distribution: {(p_dist / len(train_loader)).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79a27ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./develop_checkpoint/contrastive_trained_model.pth\")\n",
    "torch.save(embedding_projector.state_dict(), \"./develop_checkpoint/contrastive_trained_projector_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74afcfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating eval graphs: 100%|██████████| 48/48 [00:02<00:00, 21.72batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to ./submission/testset_C.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluate(test_loader, model, device, calculate_accuracy=False)\n",
    "submission_folder = os.path.join(script_dir, \"submission\")\n",
    "test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "\n",
    "os.makedirs(submission_folder, exist_ok=True)\n",
    "\n",
    "output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "\n",
    "test_graph_ids = list(range(len(predictions)))\n",
    "output_df = pd.DataFrame({\n",
    "    \"id\": test_graph_ids,\n",
    "    \"pred\": predictions\n",
    "})\n",
    "\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Predictions saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
